{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題: 映画または番組をユーザーにレコメンドする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変更元:\n",
    "- [Implementing a Recommender System with SageMaker, MXNet, and Gluon](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/gluon_recommender_system/gluon_recommender_system.ipynb)\n",
    "- [An Introduction to Factorization Machines with MNIST](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/factorization_machines_mnist/factorization_machines_mnist.ipynb)\n",
    "- [Extending Amazon SageMaker Factorization Machines Algorithm to Predict Top X Recommendations](https://aws.amazon.com/blogs/machine-learning/extending-amazon-sagemaker-factorization-machines-algorithm-to-predict-top-x-recommendations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ビジネスシナリオの概要\n",
    "\n",
    "あなたは、オンデマンド動画ストリーミングサービスをユーザーに提供することに重点を置いたスタートアップに勤務しています。会社では、ユーザーの閲覧履歴に基づいて映画/番組のレコメンデーションを提供するサービスの導入を検討しています。\n",
    "\n",
    "そのため、ユーザーウェブサイトで使用するレコメンデーションエンジンを機械学習を利用して作成し、この問題の一部を解決するように指示されました。ユーザー選好の履歴とユーザーが視聴した映画のデータセットへのアクセスが許可されています。このデータセットを使用して機械学習モデルをトレーニングし、視聴する映画/番組のレコメンデーションをユーザーに提供できます。\n",
    "\n",
    "## このデータセットについて  \n",
    "Amazon Customer Reviews Dataset は、Amazon.com マーケットプレイスで 1995 年から 2015 年までの間に販売されたさまざまな商品のレビューのコレクションです。カスタマーレビューは、Amazon で最も重要なデータタイプの 1 つです。レビューの収集と表示は、創業当初から Amazon の企業文化の一部となっており、イノベーションを生み出す重要な源の 1 つであることはほぼ間違いありません。このデータセットの詳細については、[Amazon Customer Reviews Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) を参照してください。\n",
    "\n",
    "この演習では、動画のレビューに焦点を合わせます。この動画データセットには、16 万個のデジタル動画に関する、200 万人を上回る Amazon のお客様からの 1～5 個の星による評価が含まれます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量\n",
    "\n",
    "**データ列**\n",
    "\n",
    "- `marketplace`: 2 文字の国コード (この場合、すべて \"US\")\n",
    "- `customer_id`: 1 人の作成者によって書かれたレビューを集約するために使用できるランダムな識別子\n",
    "- `review_id`: レビューの一意の ID\n",
    "- `product_id`: Amazon Standard Identification Number (ASIN)。http://www.amazon.com/dp/&lt;ASIN\\> から商品の詳細ページにアクセスできる\n",
    "- `product_parent`: その ASIN の親商品。複数の ASIN (同じ商品の色または形のバリエーション) を 1 つの親商品にまとめることができる\n",
    "- `product_title`: 商品のタイトル説明\n",
    "- `product_category`: レビューをグループ化するために使用できる広範な商品カテゴリ (この場合、デジタル動画)\n",
    "- `star_rating`: 商品の評価 (1～5 個の星)\n",
    "- `helpful_votes`: レビューに対する「役に立った」の投票数\n",
    "- `total_votes`: レビューで受け取った投票の合計数\n",
    "- `vine`: Vine プログラムの一環として書かれたレビューか?\n",
    "- `verified_purchase`: 確認済みの購入者からのレビューか?\n",
    "- `review_headline`: レビュー自体のタイトル\n",
    "- `review_body`: レビューのテキスト\n",
    "- `review_date`: レビューが作成された日付\n",
    "\n",
    "\n",
    "**データ形式**\n",
    "- 引用符またはエスケープ文字なしのタブ `\\t` 区切りのテキストファイル\n",
    "- 各ファイルの最初の行はヘッダー。1 行が 1 レコードに相当する\n",
    "\n",
    "### データセットの属性\n",
    "\n",
    "ウェブサイト: https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "\n",
    "このデータセットは Amazon の許可を得て提供されているもので、AWS デジタルトレーニングサービス契約 (https://aws.amazon.com/training/digital-training-agreement から入手可能) の条件が適用されます。このラボの実施以外の目的でデータセットをコピー、変更、販売、エクスポート、使用することは明示的に禁止されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ブレインストーミングと問題の設計\n",
    "\n",
    "(機械学習で解答できる問題)\n",
    "\n",
    "ほとんどのプロジェクトでは最初のステップとして、答えを必要とする問題、利用可能なデータはこの問題をどのようにサポートするか、問題の答えを得るためにどのツール (この場合、機械学習モデル) を使用するかについて考えます。これは、探索の範囲を絞り込み、使用する特徴量を明確にするのに役立つため、重要なステップです。\n",
    "\n",
    "少し時間を取って、以下のセルにこのデータセットに関する自分の考えを入力します。機械学習を使って予測できるものは何でしょうか? それがビジネス/クライアントの観点から関連があると思われるのはなぜですか? これらの考えが重要であると考える理由を説明します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your thoughts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの処理方法についてはいくつかのアイデアがあると思いますが、ここでは私たち全員が、特定のユーザーに動画をレコメンドする作業に取り組みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レコメンデーションと因数分解機\n",
    "\n",
    "レコメンダシステムは、いろいろな意味で機械学習の現在の人気に火を付けました。Amazon の最初期の成功例の 1 つは、\"この商品を買った人はこんな商品も買っています\" 機能です。賞金 100 万ドルの Netflix Prize により、研究に拍車がかかるとともに一般の認識が高まり、他の多くのデータサイエンスに関するコンテストが生まれるきっかけとなりました。\n",
    "\n",
    "レコメンダシステムでは、多数のデータソースと機械学習アルゴリズムを利用できます。ほとんどのシステムでは、教師なし学習、教師あり学習、強化学習というさまざまな学習手法を組み合わせて総合的なフレームワークを構築しています。ただし、中核となるコンポーネントはほとんどの場合、特定の商品に対するユーザーの評価 (または購入) を、同様の商品に対するユーザーの評価履歴および他の類似ユーザーの行動に基づいて予測するモデルです。これに必要な最小限のデータセットは、ユーザーによる商品の評価履歴です (保有しています)。\n",
    "\n",
    "使用する手法は、因数分解機です。因数分解機は、分類タスクと回帰タスクの両方に使用できる汎用的な教師あり学習アルゴリズムです。これは線形モデルの拡張であり、高次元スパースデータセット内の特徴量間の相互作用を倹約的に (単純に) キャプチャするように設計されています。このため、クリック予測、商品レコメンデーションなど、特徴量を使用してデータパターンを処理する際の適切な候補となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 1: 問題の定式化とデータ収集\n",
    "\n",
    "このプロジェクトを始めるにあたり、このシナリオにおけるビジネス上の問題と達成しようとしているビジネス目標を 2、3 文にまとめて、以下に入力します。これには、チームが目指す必要のあるビジネスメトリクスを含めます。その情報を定義したら、機械学習の問題文を明確に書き出します。最後に、これが表す機械学習のタイプに関するコメントを 1、2 文追加します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: これらの詳細の要約をプロジェクトプレゼンテーションに含めます。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ビジネスシナリオをひととおり読み通してから、以下を実行します\n",
    "\n",
    "### 1.機械学習がデプロイすべき適切なソリューションかどうか、また適切なソリューションである場合はその理由を判断します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.ビジネス上の問題、成功のメトリクス、求める機械学習の出力を定式化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.取り組んでいる機械学習の問題のタイプを特定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.使用しているデータの適切性を分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定\n",
    "\n",
    "注力する領域を特定したところで、問題を解決するための作業を開始できるようにセットアップしましょう。\n",
    "\n",
    "**注意:** このノートブックは `ml.m4.xlarge` ノートブックインスタンスで作成およびテストされました。\n",
    "\n",
    "まず、以下を指定します。\n",
    "- トレーニングデータとモデルデータに使用する Amazon Simple Storage Service (Amazon S3) バケットとプレフィックス (?)。これは、ノートブックインスタンス、トレーニング、ホスティングと同じリージョン内にある必要があります。\n",
    "- トレーニングとホスティング用にデータへのアクセス権を付与するために使用する AWS Identity and Access Management (IAM) ロールの [Amazon リソースネーム (ARN)](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html)。これらの作成方法については、ドキュメントを参照してください。\n",
    "\n",
    "**注意:** ノートブックインスタンス、トレーニング、またはホスティングに複数のロールが必要な場合、`get_execution_role()` コールを適切で完全な IAM ロールの ARN 文字列に置き換えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`<LabBucketName>`** をラボアカウントに用意されたリソース名に置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the bucket and prefix according to your information\n",
    "bucket = '<LabBucketName>'\n",
    "prefix = 'sagemaker-fm' \n",
    "\n",
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、このサンプルノートブックの残りの部分に必要な Python ライブラリを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "import boto3\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add this to display all the outputs in the cell and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 2: データの前処理と可視化 \n",
    "このデータの前処理フェーズでは、データを探索して可視化し、データに対する理解を深める必要があります。まず、必要なライブラリをインポートし、データを pandas の DataFrame に読み込みます。その後、データを探索します。データセットのシェイプを確認し、作業している列と列のタイプ (数値、カテゴリ) を調べます。特徴量に対して基本的な統計を実行して、特徴量の平均と範囲を理解することを検討します。ターゲット列を詳細に調べて、その分布を判断します。\n",
    "\n",
    "### 考慮すべき具体的な質問\n",
    "1.特徴量に対して実行した基本的な統計からどのようなことを推測できますか? \n",
    "\n",
    "2.ターゲットクラスの分布から、どのようなことを推測できますか?\n",
    "\n",
    "3.データを探索することで推測できたことは他にありますか?\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: これらの質問や他の同様の質問に対する自分の回答の要約をプロジェクトプレゼンテーションに含めます。</span>\n",
    "\n",
    "まず、Amazon S3 パブリックバケットからこのノートブック環境にデータセットを取り込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the file is already in the desired path or if it needs to be downloaded\n",
    "\n",
    "base_path = '/home/ec2-user/SageMaker/project/data/AmazonReviews'\n",
    "file_path = '/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz'\n",
    "\n",
    "if not os.path.isfile(base_path + file_path):\n",
    "    subprocess.run(['mkdir', '-p', base_path])\n",
    "    subprocess.run(['aws', 's3', 'cp', 's3://amazon-reviews-pds/tsv' + file_path, base_path])\n",
    "else:\n",
    "    print('File already downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットを読み込む\n",
    "\n",
    "扱っているデータの内容を理解できるようにするために、データを pandas の DataFrame に読み込みます。\n",
    "\n",
    "**注意:** ファイルを読み込む際に `error_bad_lines=False` と設定します。そうしない場合、問題を作成するレコードの数が非常に少なくなる可能性があるためです。\n",
    "\n",
    "**ヒント:** Python の組み込みの `read_csv` 関数 ([ドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)) を使用できます。pandas の `read_csv` で `delimiter='\\t'` を使用してファイルパスを直接使用できます。\n",
    "\n",
    "例: `pd.read_csv('filename.tar.gz', delimiter = '\\t', error_bad_lines=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの最初の数行を出力します。 \n",
    "\n",
    "**ヒント**: 行を出力するには、`pandas.head(<number>)` 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、すべての列にはどのような情報が含まれているでしょうか?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの構造\n",
    "\n",
    "データにもう少し精通し、どのような特徴量が手元にあるのかを確認します。\n",
    "\n",
    "- `marketplace`: 2 文字の国コード (この場合、すべて \"US\")\n",
    "- `customer_id`: 1 人の作成者によって書かれたレビューを集約するために使用できるランダムな識別子\n",
    "- `review_id`: レビューの一意の ID\n",
    "- `product_id`: Amazon Standard Identification Number (ASIN)。http://www.amazon.com/dp/&lt;ASIN\\> から商品の詳細ページにアクセスできる\n",
    "- `product_parent`: その ASIN の親商品。複数の ASIN (同じ商品の色または形のバリエーション) を 1 つの親商品にまとめることができる\n",
    "- `product_title`: 商品のタイトル説明\n",
    "- `product_category`: レビューをグループ化するために使用できる広範な商品カテゴリ (この場合、デジタル動画)\n",
    "- `star_rating`: 商品の評価 (1～5 個の星)\n",
    "- `helpful_votes`: レビューに対する「役に立った」の投票数\n",
    "- `total_votes`: レビューで受け取った投票の合計数\n",
    "- `vine`: Vine プログラムの一環として書かれたレビューか?\n",
    "- `verified_purchase`: 確認済みの購入者からのレビューか?\n",
    "- `review_headline`: レビュー自体のタイトル\n",
    "- `review_body`: レビューのテキスト\n",
    "- `review_date`: レビューが作成された日付"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットを分析し、理解する\n",
    "\n",
    "#### データを探索する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ヒント:** 以下の問題の答えを得るために、[こちら](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html) を参照できます。\n",
    "\n",
    "**問題:** データセットに行と列はそれぞれいくつありますか?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットのサイズを確認します。 \n",
    "\n",
    "**ヒント**: DataFrame のサイズを確認するには、`<dataframe>.shape` 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** null 値が含まれている列はどれですか。また、その列には null 値がいくつ含まれていますか?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの概要を出力します。 \n",
    "\n",
    "**ヒント**: `<dataframe>.info` 関数を使用して、キーワード引数 `null_counts = True` を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** 重複する行はありますか? ある場合、いくつありますか?  \n",
    "\n",
    "**ヒント**: `dataframe.duplicated()` ([ドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated)) を使用して DataFrame をフィルタリングし、新しい DataFrame の長さを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = # Enter your code here\n",
    "\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理\n",
    "\n",
    "ここでは、使用する特徴量と、モデル向けに特徴量を準備する方法を決定します。この例では、使用する特徴量を `customer_id`、`product_id`、`product_title`、`star_rating` に限定します。レコメンデーションシステムにその他の特徴量を追加すると役立つ可能性がありますが、このノートブックの範囲を超えた大量の処理 (特にテキストデータ) が必要になります。\n",
    "\n",
    "このデータセットを小さくし、前述の列のみを使用します。 \n",
    "\n",
    "**ヒント**: 列をリストとして渡すことで、複数の列を DataFrame として選択します。例: `df[['column_name 1', 'column_name 2']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを小さくした後で、重複があるかどうかをもう一度確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = # Enter your code here\n",
    "\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** 現在データセットに重複があるのはなぜですか? データセットを小さくした後、何が変わりましたか? 重複している最初の 20 行を確認します。\n",
    "\n",
    "**ヒント**: 行を出力するには、`pandas.head(<number>)` 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ヒント:** 重複する DataFrame の最初の 2 つの要素を確認し、元の DataFrame の df にクエリを実行してデータがどのようになるのかを確認します。`query` 関数 ([ドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)) を使用できます。\n",
    "\n",
    "例:\n",
    "\n",
    "```\n",
    "df_eg = pd.DataFrame({\n",
    "            'A': [1,2,3,4],\n",
    "            'B': [\n",
    "        })\n",
    "df_eg.query('A > 1 &amp; B > 0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続行する前に、重複する行を削除します。\n",
    "\n",
    "**ヒント**: `~` 演算子を使用して重複していないすべての行を選択します。例:\n",
    "    \n",
    "```\n",
    "df_eg = pd.DataFrame({\n",
    "            'A': [1,2,3,4],\n",
    "            'B': [2,0,5,2]\n",
    "        })\n",
    "df_eg[~(df_eg['B'] > 0)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット内の一部の行を可視化する\n",
    "上記の部分でまだそうしていない場合には、以下のスペースを使用して、データの一部をさらに可視化できます。特に、`star_rating`、`customer_id`、`product_id` などの特徴量の分布を確認します。\n",
    "\n",
    "**考慮すべき具体的な質問**\n",
    "\n",
    "1.特徴量の分布を確認した結果、これらの特徴量はどの程度モデルに役立つと思われますか? これらの分布から推測できる、データの理解を深めるのに役立つと思われるものが何かありますか? \n",
    "\n",
    "2.すべてのデータを使用する必要がありますか? どの特徴量を使用する必要がありますか?\n",
    "\n",
    "3.ユーザー評価の件数が最も多い月は何月ですか?\n",
    "\n",
    "以下のセルを使用してデータを可視化し、これらの質問や他の関心を持つ質問に回答します。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: この質問や同様の質問に対する自分の回答の要約をプロジェクトプレゼンテーションに含めます。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sns.barplot` ([ドキュメント](https://seaborn.pydata.org/generated/seaborn.barplot.html)) を使用して、`star_rating` の密度と分布のグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here to count the number of reviews with a specific rating\n",
    "\n",
    "sns.barplot(\n",
    "    x='index',\n",
    "    y=<CODE>, # Enter your code here\n",
    "    data=_, # The underscore symbol in Python is used to store the output of the last operation\n",
    "    palette='GnBu_d'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** ユーザー評価の件数が最も多い月は何月ですか?  \n",
    "\n",
    "**ヒント**:  \n",
    "1.`pd.to_datetime` を使用して、`review_date` 列を datetime 列に変換します。 \n",
    "2.`review_date` 列にある月を使用します。`<column_name>.dt.month` を使用してアクセスし、datetime 列で使用できます。 \n",
    "3.`groupby` 関数で `idxmax` を使用します。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the review date to a datetime type.Here you will use original dataframe 'df'\n",
    "df['review_date'] = # Enter your code here\n",
    "\n",
    "# Count the number of ratings by month\n",
    "df.groupby(<CODE>).star_rating.count().reset_index()\n",
    "\n",
    "# Use the bar plot again to plot the ratings(y) vs. review_date(x)\n",
    "sns.barplot(x=<CODE>, y=<CODE>, data=_, palette='GnBu_d') # Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Pandas groupby function on month to get the star rating count\n",
    "max_month = df.groupby(<CODE>).star_rating.count().idxmax() # Enter your code here\n",
    "print(f'The month with the most reviews is: {max_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ボーナス問題 (オプション):** レビューの数が最も多い年と最も少ない年はどれですか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Pandas groupby function on year and get the star rating count\n",
    "df.groupby(<CODE>).star_rating.count().reset_index() # Enter your code here\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "# Use the bar plot to plot star_rating(y) vs. review_date(x)\n",
    "sns.barplot(x=<CODE>, y=<CODE>, data=_, palette='GnBu_d') # Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データをクリーンアップする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: お客様 1 人あたりのレビューの数と動画 1 つあたりのレビューの数はどのように性質が異なりますか? 分位値を使用して確認します。\n",
    "\n",
    "**ヒント**: お客様と商品の DataFrame の `<dataframe>['columns_name'].value_counts()` を使用します。そして関係を見つけるために `<dataframe>.quantile(<list>)` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = # Enter your code here\n",
    "products = # Enter your code here\n",
    "\n",
    "quantiles = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.25, 0.5,\n",
    "             0.75, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.995,\n",
    "             0.999, 1]\n",
    "print('customers\\n', <CODE>) # Enter your code here\n",
    "print('products\\n', <CODE>) # Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この長い末尾を除外します。18 個以上の動画を評価したお客様と 95 件を超えるレビューがある商品を選択します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers1 = # Enter your code here\n",
    "products1 = # Enter your code here\n",
    "\n",
    "# Use the Pandas merge function to merge the customer1 and products1 with the original df_reduced dataset\n",
    "reduced_df = (\n",
    "            df_reduced.merge(pd.DataFrame({'customer_id': customers1.index}))\n",
    "                      .merge(pd.DataFrame({'product_id': products1.index}))\n",
    "            )# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** `customers1`、`products1`、および reduced_df という新しい DataFrame のシェイプはどのようになっていますか?  \n",
    "\n",
    "**注意**: これには f-strings を使用します。\n",
    "```\n",
    "x= 3\n",
    "print(f'X = {x}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of users is {<CODE>} and number of items is {<CODE>}.')# Enter your code here\n",
    "print(f'Length of reduced df is {<CODE>}.')# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame の最初の 5 列を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** `reduced_df` では評価の比率は同じ比率に維持されていますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df[<CODE>].value_counts().reset_index()# Enter your code here\n",
    "sns.barplot(x='index', y='star_rating', data=_, palette='GnBu_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、お客様ごとのカウントと商品ごとのカウントに関するお客様の分布と商品の分布を再作成します。\n",
    "\n",
    "**ヒント**: `customer_id` 列と `product_id` 列で `value_counts()` 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = # Enter your code here\n",
    "products = # Enter your code here\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "fig.suptitle('Distribution of counts per customer and product')\n",
    "sns.distplot(customers, kde=False, ax=axs[0], color='teal')\n",
    "sns.distplot(products, kde=False, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、各ユーザーと商品に番号を付け、独自の連続インデックスを付けます。これにより、情報をスパース形式で格納できます。この形式では、連続インデックスによって評価行列の行と列が示されます。\n",
    "\n",
    "`customer_index` と `product_index` を作成するには、`customer_id` をインデックス値とし、ユーザーと商品の番号に連番/連続値を使用して新しい DataFrame を作成します。両方のインデックスの作成が完了したら、pandas の `merge` 関数を使用して `customer_index` と `product_index` をマージします。\n",
    "\n",
    "**ヒント**: お客様の合計数と商品の合計数を生成するには `shape` 関数を使用します。0 からお客様数と商品数までの番号のリストを生成するには、`np.arange` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_index = pd.DataFrame({'customer_id': customers.index,\n",
    "                               'user': np.arange(<CODE>)}) # Enter your code here\n",
    "product_index = pd.DataFrame({'product_id': products.index,\n",
    "                              'item': np.arange(<CODE>)}) # Enter your code here\n",
    "\n",
    "reduced_df = reduced_df.merge(<CODE>).merge(<CODE>)# Enter your code here\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解答例:\n",
    "<div class=\"output_subarea\"><div>\n",
    "\n",
    "<table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right\">\n",
    "      <th></th>\n",
    "      <th>customer_id</th>\n",
    "      <th>product_id</th>\n",
    "      <th>star_rating</th>\n",
    "      <th>product_title</th>\n",
    "      <th>user</th>\n",
    "      <th>item</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>11763902</td>\n",
    "      <td>B00PSLQYWE</td>\n",
    "      <td>4</td>\n",
    "      <td>ダウントンアビー シーズン 5</td>\n",
    "      <td>3065</td>\n",
    "      <td>103</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>1411480</td>\n",
    "      <td>B00PSLQYWE</td>\n",
    "      <td>5</td>\n",
    "      <td>ダウントンアビー シーズン 5</td>\n",
    "      <td>130</td>\n",
    "      <td>103</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>35303629</td>\n",
    "      <td>B00PSLQYWE</td>\n",
    "      <td>5</td>\n",
    "      <td>ダウントンアビー シーズン 5</td>\n",
    "      <td>4683</td>\n",
    "      <td>103</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>21285980</td>\n",
    "      <td>B00PSLQYWE</td>\n",
    "      <td>5</td>\n",
    "      <td>ダウントンアビー シーズン 5</td>\n",
    "      <td>449</td>\n",
    "      <td>103</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>29260449</td>\n",
    "      <td>B00PSLQYWE</td>\n",
    "      <td>5</td>\n",
    "      <td>ダウントンアビー シーズン 5</td>\n",
    "      <td>131</td>\n",
    "      <td>103</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">ラボ 2 の終わり</span>\n",
    "\n",
    "ローカルコンピュータにプロジェクトファイルを保存します。次の一連のステップを実行します。\n",
    "\n",
    "1.ページ上部にある [**File**] メニューをクリックします。\n",
    "\n",
    "1.[**Download as**] を選択し、[**Notebook(.ipynb)**] をクリックします。 \n",
    "\n",
    "これにより、現在のノートブックがコンピュータのデフォルトのダウンロードフォルダにダウンロードされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 3: モデルのトレーニングと評価\n",
    "\n",
    "データセットを DataFrame から機械学習アルゴリズムで使用できる形式に変換するときに、実行する必要がある準備手順があります。Amazon SageMaker の場合、以下の手順を実行する必要があります。\n",
    "\n",
    "1.データを `train_data` と `test_data` に分割します。   \n",
    "2.Amazon SageMaker トレーニングジョブで使用できる適切なファイル形式にデータセットを変換します。これは CSV ファイルまたは record protobuf のいずれかです。詳細については、[トレーニングの共通データ形式](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html) を参照してください。この問題の場合、データはスパースになるため、`scipy.sparse.lilmatrix` 関数を使用し、その後 `sagemaker.amazon.common.write_spmatrix_to_sparse_tensor` を使用してこの関数を `RecordIO protobuf` 形式に変換できます。   \n",
    "3.Amazon S3 バケットにデータをアップロードします。バケットを作成したことがない場合は、[バケットの作成](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html) を参照してください。   \n",
    "\n",
    "以下のセルを使用して、これらの手順を完了します。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: このフェーズでの主な決定事項をプロジェクトプレゼンテーションに記録します。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データを準備する\n",
    "\n",
    "これで、データセットをモデルの入力として準備する作業を開始できます。モデルによって入力のニーズは異なります。Amazon SageMaker に実装されているアルゴリズムの一部には、recordIO でラップされた protobuf 形式のデータが必要です。この処理は、以下のセルで行います。\n",
    "\n",
    "まず、データセットをトレーニングセットとテストセットに分割します。これにより、お客様が評価した動画のうち、トレーニングに含まれていなかった動画に対するモデルの精度を推測できます。\n",
    "\n",
    "`test_df` DataFrame の作成から始めます。`customer_id` で DataFrame をグループ化し、`pd.groupby(' ').last()` に似た `last` 関数を使用して DataFrame を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = reduced_df.groupby(<CODE>).last().reset_index() # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングデータを作成するには、`test_df` にある値を `reduced_df` DataFrame から削除します。\n",
    "\n",
    "**ヒント**: `customer_id` 列と `product_id` 列を外部結合として使用して、`reduced_df` DataFrame と `test_df` データセットをマージします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "train_df = reduced_df.merge(<CODE>,\n",
    "                            on=['customer_id', 'product_id'],\n",
    "                            how='outer',\n",
    "                            indicator=True,\n",
    "                            indicator=True)\n",
    "train_df = train_df[(train_df['_merge'] == 'left_only')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、データのいくつかの基本的な特性を確認できるようになりました。これは、後でモデルのトレーニングのために特徴量を適切な形式に変換するのに役立ちます。\n",
    "\n",
    "テストデータセットとトレーニングデータセットの長さに関して 2 つの変数 `nb_rating_test` と `nb_ratings_train` を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ratings_test = # Enter your code here\n",
    "nb_ratings_train = # Enter your code here\n",
    "print(f\" Training Count: {nb_ratings_train}\")\n",
    "print(f\" Test Count: {nb_ratings_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの変換\n",
    "\n",
    "これで、pandas の DataFrame をスパース行列に変換できます。このプロセスは、トレーニングとテストの両方で同じです。Amazon SageMaker での因数分解機の実装では recordIO でラップされた protobuf を使用します。ここでは、現在持っているデータはディスク上の pandas の DataFrame です。そのため、データをスパース行列に変換して、各ユーザーと各映画の関係を表現します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def loadDataset(df, lines, columns, regressor=True):\n",
    "    \"\"\"\n",
    "    Convert the pandas dataframe into a sparse matrix\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        lines: number of rows of the final sparse matrix\n",
    "        columns: number of columns of final sparse matrix\n",
    "        regressor: Boolean value to check if using regression\n",
    "                  or classification\n",
    "    Returns:\n",
    "        X: Feature vector\n",
    "        Y: Label vector\n",
    "    \"\"\"\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    \n",
    "    # Use scipy.sparse.lil_matrix to create the feature vector X of type float32\n",
    "    # The size of the matrix is the length of the dataframe and \n",
    "    # number of lines plus number of columns variable \n",
    "    X = lil_matrix((<CODE>, lines + columns)).astype('float32') # Enter your code here\n",
    "    \n",
    "    # Labels are stored in a vector.Instantiate an empty label vector Y.\n",
    "    Y = # Enter your code here\n",
    "    \n",
    "    line = 0\n",
    "    \n",
    "    # For each row in the dataframe, use 1 for the item and product number\n",
    "    for index, row in df.iterrows():\n",
    "        X[line,row['user']] = 1\n",
    "        X[line, lines + (row['item'])] = 1\n",
    "        line += 1\n",
    "\n",
    "        if regressor:\n",
    "            # If using regression, append the star_rating from the row variable\n",
    "            Y.append(<CODE>) # Enter your code here\n",
    "        else:\n",
    "            # Use 1 for star_rating 5 else use 0 from the row variable\n",
    "            if int(row['star_rating']) >= 5:\n",
    "                Y.append(<CODE>) # Enter your code here\n",
    "            else:\n",
    "                Y.append(<CODE>) # Enter your code here\n",
    "            \n",
    "    # Convert the list into a NumPy array of type float32     \n",
    "    Y = np.array(<CODE>).astype('float32') # Enter your code here\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loadDataset` 関数を使用してトレーニングセットとテストセットを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customers.shape[0],\n",
    "      products.shape[0],\n",
    "      customers.shape[0] + products.shape[0])\n",
    "\n",
    "# Use loadDataset function with train_df, customers.shape[0] and products.shape[0]\n",
    "X_train, Y_train = loadDataset(<CODE>) # Enter your code here\n",
    "\n",
    "# Use loadDataset function with test_df, customers.shape[0] and products.shape[0]\n",
    "X_test, Y_test = loadDataset(<CODE>) # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データがスパース形式になったので、protobuf 形式で保存し、Amazon S3 にアップロードします。この手順は難しそうな印象を与えるかもしれませんが、変換処理のほとんどは、以下で SageMaker としてインポートされる Amazon SageMaker Python SDK によって行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "def writeDatasetToProtobuf(X, bucket, prefix, key, d_type, Y=None):\n",
    "    buf = io.BytesIO()\n",
    "    if d_type == \"sparse\":\n",
    "        smac.write_spmatrix_to_sparse_tensor(buf, X, labels=Y)\n",
    "    else:\n",
    "        smac.write_numpy_to_dense_tensor(buf, X, labels=Y)\n",
    "        \n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "\n",
    "\n",
    "fm_train_data_path = writeDatasetToProtobuf(X_train, bucket, prefix, 'train', \"sparse\", Y_train)    \n",
    "fm_test_data_path = writeDatasetToProtobuf(X_test, bucket, prefix, 'test', \"sparse\", Y_test)  \n",
    "  \n",
    "print(\"Training data S3 path: \", fm_train_data_path)\n",
    "print(\"Test data S3 path: \", fm_test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでデータの準備は完了です。成功です。 これでわかるように、モデルを作成するためにデータをクリーンアップして準備するには、多くの時間と労力が必要です。これはすべてのデータサイエンスプロジェクトに当てはまります。そして、このステップは結果に大きな影響を与えます。今後のすべての機械学習プロジェクトで、トレーニングのためにデータを理解し、準備する時間を十分に取るようにしてください!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルをトレーニングする\n",
    "\n",
    "ここでは、モデルをトレーニングします。トレーニングには、Amazon SageMaker トレーニングジョブを使用します。Amazon SageMaker トレーニングジョブを使用すると、トレーニング用のすべてのコードを記述する必要がないため、モデルを簡単に作成できます。コードは既にコンテナ形式に処理されています。\n",
    "\n",
    "ノートブックからトレーニングジョブを作成する一般的なワークフローでは、予測子をインスタンス化し、いくつかのハイパーパラメータを渡し、データを正しい形式で渡します。以下のセルでこれを実行します。\n",
    "\n",
    "FM 推定器の詳細については、[FactorizationMachines](https://sagemaker.readthedocs.io/en/stable/factorization_machines.html) を参照してください。\n",
    "\n",
    "ハイパーパラメータの詳細については、[因数分解機のハイパーパラメータ](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines-hyperparameters.html) を参照してください。\n",
    "\n",
    "**ヒント**: 例:\n",
    "\n",
    "```\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "pca = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                    role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_location,\n",
    "                                    sagemaker_session=sess)\n",
    "                                    \n",
    "pca.set_hyperparameters(featuer_dim=50000,\n",
    "                        num_components=10,\n",
    "                        subtract_mean=True,\n",
    "                        algorithm_mode='randomized',\n",
    "                        mini_batch_size=200)\n",
    "                        \n",
    "pca.fit({'train': s3_train_data})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris\n",
    "\n",
    "output_prefix = 's3://' + bucket + '/sagemaker-fm/model'\n",
    "instance_type= # Enter your code here\n",
    "batch_size = # Enter your code here\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(\n",
    "    image_uris.retrieve(boto3.Session().region_name, \"factorization-machines\"),\n",
    "    role,\n",
    "    instance_count=<CODE>, # Enter your code here\n",
    "    instance_type=instance_type,\n",
    "    output_path=output_prefix,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "# Use hyperparameter.For feature_dim use the column length of X_train \n",
    "fm.set_hyperparameters(\n",
    "                        feature_dim=<CODE>, # Enter your code here\n",
    "                        predictor_type='regressor',\n",
    "                        mini_batch_size=batch_size,\n",
    "                        num_factors=64,\n",
    "                        epochs=25,\n",
    "                        clip_gradient=5.0,\n",
    "                        rescale_grad=1.0/batch_size\n",
    ")\n",
    "\n",
    "fm.fit({'train': ,# Enter your code here,\n",
    "        'test': # Enter your code here\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** `batch_size` と `epochs` を変更すると、最終的なメトリクスはどうなりますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** モデルの出力を確認します。使用されているメトリクスにはどのような意味がありますか? トレーニングセットとテストセットには違いがありますか? ある場合、それにはどのような意味がありますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価する\n",
    "\n",
    "お疲れ様でした。 Amazon SageMaker トレーニングジョブが正常に開始されました。次はどうしますか? モデルが一貫した値を実際に予測していることを確認するための手段が必要です。どのようにこれを行いますか?\n",
    "\n",
    "まず、モデルのパフォーマンスを概算するために単純ベースラインを計算します。最も簡単な概算方法は、ユーザーのどの商品評価も単にすべての評価の平均評価であると仮定することです。基本的にいえば、すべてのレビューの平均値を出力することのみを学習したモデルを持つということです。\n",
    "\n",
    "**注意:** 個別の動画の平均を使用すると改善できる可能性がありますが、ここでは、同じ結論に行き着くため、重要ではありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`star_rating` の平均を計算して `naive_guess` を求めます。次に、テスト `star_rating` からの単純予測を 2 乗し、平均値を求めることで、単純 MSE を計算します。\n",
    "\n",
    "$average(test(star\\_rating) - naive\\_guess)^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naive_guess = np.mean(<CODE>) # Enter your code here\n",
    "print(f'Naive MSE:', np.mean((<CODE>)**2)) # Enter your code here )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、テストデータセットの予測を計算します。これを行うには、トレーニングしたモデルを_デプロイ_する必要があります。\n",
    "\n",
    "**注意:** これは、上記の CloudWatch の出力に密接に連携しますが、`eval_net` 関数で部分的なミニバッチをスキップするため、若干異なる可能性があります。\n",
    "\n",
    "`<estimator_name>.deploy` を使用して `initial_instance_count=1, instance_type=ml.m4.xlarge` を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor = # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エンドポイントが 'InService' になったので、テストセットでのモデルのパフォーマンスを評価します。テストセットでのパフォーマンスとトレーニングセットでのパフォーマンスを比較します。\n",
    "\n",
    "### 考慮すべき主な質問:\n",
    "1.テストセットでのモデルのパフォーマンスはトレーニングセットでのパフォーマンスと比べてどのように異なりますか? この比較からどのようなことを推測できますか? \n",
    "\n",
    "2.正解率、適合率、再現率などのメトリクスの結果に明らかな違いはありますか? ある場合、そのような違いが見られる理由は何だと思われますか? \n",
    "\n",
    "3.ビジネスの状況と目標を考えると、ここで考慮すべき最も重要なメトリクスはどれですか? それはなぜですか?\n",
    "\n",
    "4.最も重要だと考えるメトリクスの結果は、ビジネスの観点でのニーズを十分に満たすものですか? そうでない場合、次のイテレーション (次の特徴量エンジニアリングのセクション) の際に何を変更できると思いますか? \n",
    "\n",
    "以下のセルを使用して、これらの質問や他の質問に答えてください。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: このセクションで回答するこれらの質問や他の同様の質問をプロジェクトプレゼンテーションに記録します。主な詳細と決定事項をプロジェクトプレゼンテーションに記録します。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デプロイプロセスでは、トレーニングして Amazon S3 に保存したモデルを使用して、指定されたサイズ (この場合は `ml.m4.xlarge`) のインスタンスを作成する必要があります。予測を取得するには、JSON のシリアル化された形式でデータを渡す必要があります。推論から取得する出力もシリアル化された JSON 形式になるため、予測値を取得するために出力を逆シリアル化する必要もあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a serializer function for the predictor\n",
    "import json\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import BaseSerializer\n",
    "\n",
    "class fm_serializer(BaseSerializer):\n",
    "    CONTENT_TYPE='application/json'\n",
    "    def serialize(data):\n",
    "            js = {'instances': []}\n",
    "            for row in data:\n",
    "                js['instances'].append({'features': row.tolist()})\n",
    "            return json.dumps(js)\n",
    "fm_predictor.serializer = fm_serializer\n",
    "fm_predictor.deserializer = JSONDeserializer()\n",
    "print(f\"Accepted content type: {fm_predictor.content_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングセットの動作を確認します。エンドポイントを使用して、モデルから予測を取得します。\n",
    "\n",
    "まず、1 つの予測がどのようになるのかを調べます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker モデルコンテナでは、リクエストに 60 秒以内に応答します。モデル自体は、呼び出しに応答するまで 60 秒の最大処理時間をかけることができます。これを行うには、一度に 5 行分に対して `predict` 関数を呼び出し、それらの行をリストに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the X_train data to the deployed predictor \n",
    "ytrain_p = []\n",
    "for i in range(0, 1000, 5):\n",
    "    preds = fm_predictor.predict(<CODE>)<CODE> # Enter your code here\n",
    "    p = [ytrain_p.append(x['score']) for x in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** 推論を取得したので、サニティーチェックを実行します。推論で予測された最小値と最大値は何ですか? それらは、トレーニングデータの最小値と最大値に対応していますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The minimum rating predicted is: ', <CODE>, # Enter your code here\n",
    "      'and the maximum is: ', <CODE> # Enter your code here\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、テストデータセットを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** 予測での最小値と最大値はどのような点で似ていますか? 分布全体 (ヒストグラム) を確認した場合は、ボーナスポイントを獲得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(Y_pred), min(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Y_pred, kde=False, bins=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、テストセットの平均二乗誤差を計算し、ベースラインからどの程度改善されているかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:', <CODE> )# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レコメンダシステムでは、主観的な正確さも重要です。ランダムに選択したユーザーのレコメンデーションを取得し、直感的に適切かどうかを確認します。\n",
    "\n",
    "ユーザー番号 200 を使用し、このユーザーが何を視聴し、何に高い評価を付けたのかを確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df[<CODE>].sort_values(\n",
    "    ['star_rating', 'item'], ascending=[False, True]) # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ご覧のように、このユーザーはコメディ映画、ロマンス映画、陽気な映画を視聴するのが好きで、ドラマやファンタジー映画を視聴するのは嫌いです。モデルでは、このユーザーによる映画の評価をどのように予測するのか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_predictions(user_id, number_movies, columns):\n",
    "    # Create the sparse matrix similar to the one for training data\n",
    "    X = il_matrix((<CODE>)).astype('float32')# Enter your code here\n",
    "    movie_index_start = columns - number_movies\n",
    "\n",
    "    # Fill out the matrix.Each row will be the same user with every possible movie.\n",
    "    for row in range(number_movies):\n",
    "        X[row, user_id - 1] = <CODE> # Enter your code here\n",
    "        X[row, movie_index_start + row] = <CODE> # Enter your code here\n",
    "\n",
    "    return X\n",
    "\n",
    "user_200 = prepare_predictions(200,\n",
    "                               <CODE> # Enter your code here ,\n",
    "                               <CODE> # Enter your code here\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、モデルで予測する、ユーザー 200 がすべての映画に付ける評価のリストを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_200 = []\n",
    "for i in range(0, <CODE>):\n",
    "    preds = fm_predictor.predict(<CODE>)['predictions']\n",
    "    p = [pred_200.append(x['score']) for x in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、カタログ内のすべての一般的な動画について、ユーザー 200 の評価をループ処理して予測し、レコメンドする動画としない動画を確認します。\n",
    "\n",
    "`reduced_df` DataFrame を使用して商品別にグループ化し、`titles` という新しい DataFrame を作成します。`product_title` 列を使用して、もう 1 つの列 `score` を作成し、`pred_200` からの値を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = reduced_df.groupby(<CODE>)[<CODE>].first().reset_index()\n",
    "titles['score'] = # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** 最高スコアを獲得した商品はどれですか?  \n",
    "\n",
    "**ヒント**: `sort_values` 関数を使用して `score` 列と `item` 列を並べ替え、パラメータ `asecnding=[False,True]` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** このユーザーが高く評価する番組と最も低く評価する番組からどのような結論を導くことができますか? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レコメンデーションに、他のユーザーとの相関関係があるかどうかを確認します。ユーザー 201 を試してみます。ユーザー 200 に対して行ったのと同じ操作を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_201 = prepare_predictions(<CODE>, products.shape[0], customers.shape[0] + products.shape[0])\n",
    "\n",
    "pred_201 = []\n",
    "for i in range(0, user_201.shape[0], 5):\n",
    "    preds = fm_predictor.predict(user_201[i:i+5].toarray())['predictions']\n",
    "    p = [pred_201.append(x['score']) for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred_200, pred_201)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** 2 人のユーザーの散布図からどのような結論を導くことができますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論のために作成したエンドポイントはもう使用しないため、削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(fm_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">ラボ 3 の終わり</span>\n",
    "\n",
    "ローカルコンピュータにプロジェクトファイルを保存します。次の一連のステップを実行します。\n",
    "\n",
    "1.ページ上部にある [**File**] メニューをクリックします。\n",
    "\n",
    "1.[**Download as**] を選択し、[**Notebook(.ipynb)**] をクリックします。 \n",
    "\n",
    "これにより、現在のノートブックがコンピュータのデフォルトのダウンロードフォルダにダウンロードされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# イテレーション 2\n",
    "\n",
    "# ステップ 4: 特徴量エンジニアリング\n",
    "\n",
    "これで、モデルのトレーニングと評価の 1 回目のイテレーションを完了しました。モデルで最初に得られた結果はビジネス上の問題を解決するにはおそらく不十分だったと仮定すると、モデルのパフォーマンスを改善できるようにするためにデータに関して何を変更できると思いますか?\n",
    "\n",
    "### 考慮すべき主な質問:\n",
    "1.機械学習の問題を変更することは、データセットに対してどのように役立ちますか? 回帰を使用して問題を解決しようとしましたが、分類は役立つでしょうか?\n",
    "2.この機械学習の問題を機械学習の分類問題に変更するには何をする必要がありますか? 新しい分類の問題文を書き出してください。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: 主な決定事項とこのセクションで使用する手法をプロジェクトプレゼンテーションに記録します。また、モデルを再び評価した後に取得する新しいパフォーマンスメトリクスも記録します。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、取得した評価に応じてバイナリ出力を行うようトレーニングデータセットを変更します。評価が 5 つ星の場合、ユーザーに何かをレコメンドすることを検討します。今回も Amazon S3 に protobuf 形式で保存します。以下を実行します。  \n",
    "\n",
    "1.`loadDataset` 関数を使用してオプション `regression=False` を指定し、トレーニングデータセットを作成します。  \n",
    "2.データセットを protobuf 形式で書き込みます。 \n",
    "3.`predictor_type='binary_classifier'` を使用してモデルを再トレーニングします。  \n",
    "4.以前にテストセットに対して行ったときと同様に、エンドポイントにモデルをデプロイし、モデルを評価します。  \n",
    "5.混同行列を使用して、テストセットでの結果を調べます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class, Y_train_class = # Enter your code here\n",
    "X_test_class, Y_test_class = # Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataset as a protobuf\n",
    "fm_train_data_path = writeDatasetToProtobuf(<CODE>) # Enter your code here    \n",
    "fm_test_data_path = writeDatasetToProtobuf(<CODE>) # Enter your code here    \n",
    "  \n",
    "print(\"Training data S3 path: \", fm_train_data_path)\n",
    "print(\"Test data S3 path: \", fm_test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルコード\n",
    "\n",
    "```\n",
    "fm_train_data_path = writeDatasetToProtobuf(X_train_class, bucket, prefix, 'train_class', \"sparse\", Y_train_class)    \n",
    "fm_test_data_path = writeDatasetToProtobuf(X_test_class, bucket, prefix, 'test_class', \"sparse\", Y_test_class) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、回帰から二項分類に変更して、モデルを再トレーニングします。以前にモデルをトレーニングしたときと同じコードと設定を使用しますが、`predictor_type='binary_classifier` を変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Retrain your model\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルコード \n",
    "```\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris\n",
    "\n",
    "#output_prefix= 's3://<LabBucketName>/sagemaker-fm/model'\n",
    "\n",
    "output_prefix = 's3://' + bucket + '/sagemaker-fm/model'\n",
    "instance_type='ml.m4.xlarge'\n",
    "batch_size = 512\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(\n",
    "    image_uris.retrieve(\"factorization-machines\",boto3.Session().region_name),\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    output_path=output_prefix,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=X_train.shape[1],\n",
    "                     # predictor_type='regressor',\n",
    "                       predictor_type='binary_classifier',\n",
    "                       mini_batch_size=batch_size,\n",
    "                       num_factors=128,\n",
    "                       epochs=25,\n",
    "                       clip_gradient=5.0,\n",
    "                       rescale_grad=1.0/batch_size\n",
    "                       )\n",
    "\n",
    "fm.fit({'train': fm_train_data_path, 'test': fm_test_data_path})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この新しいモデルのパフォーマンスを評価します。モデルをデプロイし、シリアライザを決定し、テストデータを渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import deserializers\n",
    "fm_predictor = fm.deploy(initial_instance_count=1,\n",
    "                         instance_type='ml.m4.xlarge',\n",
    "                         serializer=fm_serializer,\n",
    "                         deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the testing data to the classifier and get all the predictions\n",
    "Y_pred = []\n",
    "for i in range(0, X_test_class.shape[0], 5):\n",
    "    preds = fm_predictor.predict(X_test_class[i:i+5].toarray())['predictions']\n",
    "    p = [Y_pred.append(x['score']) for x in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 結果を確認する\n",
    "\n",
    "分類器のパフォーマンスを調べるために、混同行列を計算してグラフを作成します。**Scikit-Learn** の実装を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = Y_test_class.astype(int)\n",
    "predicted = [1 if value > 0.5 else 0 for value in Y_pred]\n",
    "conf_matrix = confusion_matrix(true, predicted)\n",
    "print(conf_matrix)\n",
    "sns.heatmap(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** モデルの精度はどれくらいですか?  \n",
    "\n",
    "**ヒント**:\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + FP + FN + TN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** すべてを 1 と予測する単純ベースラインモデルと比較して、今回のモデルの結果はどうでしたか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(reduced_df.star_rating > 4).value_counts() / reduced_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete inference endpoint\n",
    "sagemaker.Session().delete_endpoint(fm_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN で能力を統合する\n",
    "\n",
    "分類器モデルの方が回帰モデルよりも優れていることがわかりました。ここでは、評価 (回帰) したり、ユーザーが映画を好きかどうか (二項分類) を予測したりするのではなく、K 近傍法 (KNN) モデルに適合するようにモデルを再パッケージして、お客様が好きな商品の **K 近傍**商品を予測し、それをお客様にレコメンドできるかどうかを確認します。\n",
    "\n",
    "まず、Amazon S3 からモデルをダウンロードします。次に、KNN モデルに適合するようにモデルを再パッケージします。\n",
    "\n",
    "**注意:** 次のセルを実行できるようにするために、使用しているカーネルが `conda_mxnet_p36` であることを確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルデータをダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "model_file_name = 'model.tar.gz'\n",
    "model_full_path = f'{fm.output_path}/{fm.latest_training_job.job_name}/output/{model_file_name}'\n",
    "print(f'Model Path: {model_full_path}')\n",
    "\n",
    "# Download FM model \n",
    "os.system('aws s3 cp ' + model_full_path + ' .')\n",
    "\n",
    "# Extract model file for loading to MXNet\n",
    "os.system('tar xzvf ' + model_file_name)\n",
    "os.system('unzip -o model_algo-1')\n",
    "os.system('mv symbol.json model-symbol.json')\n",
    "os.system('mv params model-0000.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルデータを抽出して、商品とユーザーの潜在行列を作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、因数分解機をトレーニングした後で、各ユーザーと商品を表す値を抽出します。トレーニングの結果は、一緒に乗算したときにターゲット値 (0 または 1) を可能な限り厳密に表す 2 つの行列です。\n",
    "\n",
    "より数学的にいうと、因数分解機モデルの出力は 3 つの N 次元配列 (ndarray) で構成されます:\n",
    "\n",
    "    V – a (N x k) 行列では:\n",
    "        k は潜在空間の次元\n",
    "        N はユーザーと商品の合計数\n",
    "    w – N 次元ベクトル\n",
    "    b – 単一の数値: バイアス項\n",
    "\n",
    "特徴量として使用するこれらの値を抽出するには、まず、モデルを読み込む必要があります。次に、3 つの行列のそれぞれから値を抽出し、`knn_item_matrix` 行列と t`knn_user_matrix` 行列を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model data\n",
    "m = mx.module.Module.load('./model', 0, False, label_names=['out_label'])\n",
    "V = m._arg_params['v'].asnumpy()\n",
    "w = m._arg_params['w1_weight'].asnumpy()\n",
    "b = m._arg_params['w0_weight'].asnumpy()\n",
    "\n",
    "nb_users = customers.shape[0]\n",
    "nb_item = products.shape[0]\n",
    "\n",
    "# Item latent matrix - concat(V[i], w[i]). \n",
    "knn_item_matrix = np.concatenate((V[nb_users:], w[nb_users:]), axis=1)\n",
    "knn_train_label = np.arange(1,nb_item+1)\n",
    "\n",
    "# User latent matrix - concat (V[u], 1) \n",
    "ones = np.ones(nb_users).reshape((nb_users, 1))\n",
    "knn_user_matrix = np.concatenate((V[:nb_users], ones), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN モデルを構築する\n",
    "\n",
    "トレーニングデータを取得したので、そのデータを KNN モデルに提供できるようになりました。前回と同様、protobuf IO 形式のデータを Amazon S3 に保存し、モデルをインスタンス化し、ハイパーパラメータを設定する必要があります。\n",
    "\n",
    "まず、パスと推定器を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN train features shape = ', knn_item_matrix.shape)\n",
    "knn_prefix = 'knn'\n",
    "train_key = 'train_knn'\n",
    "knn_output_prefix = f's3://{bucket}/{knn_prefix}/output'\n",
    "knn_train_data_path = writeDatasetToProtobuf(knn_item_matrix, bucket,\n",
    "                                             knn_prefix, train_key,\n",
    "                                             \"dense\",\n",
    "                                             knn_train_label)\n",
    "print(f'Uploaded KNN train data: {knn_train_data_path}')\n",
    "\n",
    "nb_recommendations = 100\n",
    "\n",
    "# Set up the estimator\n",
    "knn = sagemaker.estimator.Estimator(\n",
    "    image_uris.retrieve(\"knn\",boto3.Session().region_name),\n",
    "    get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    output_path=knn_output_prefix,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、ハイパーパラメータを設定します。この手法では、KNN にデフォルトの `index_type` パラメータを使用することに注意してください。正確ですが、大きなデータセットでは動作が遅くなる可能性があります。そのような場合には、概算ではありますが迅速に答えを得ることのできる、別の `index_type` パラメータを使用することもできます。\n",
    "\n",
    "インデックスのタイプの詳細については、[k-NN ハイパーパラメータ](https://docs.aws.amazon.com/sagemaker/latest/dg/kNN_hyperparameters.html) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "knn.set_hyperparameters(feature_dim=knn_item_matrix.shape[1],\n",
    "                        k=nb_recommendations,\n",
    "                        index_metric=\"INNER_PRODUCT\",\n",
    "                        predictor_type='classifier',\n",
    "                        sample_size=200000)\n",
    "\n",
    "\n",
    "knn.fit({'train': knn_train_data_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニング済みのモデルが完成したので、バッチ推論で参照できるように保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_name = knn.latest_training_job.job_name\n",
    "print(\"created model: \", knn_model_name)\n",
    "\n",
    "# Save the model so that you can reference it in the next step during batch inference\n",
    "sm = boto3.client(service_name='sagemaker')\n",
    "primary_container = {\n",
    "    'Image': knn.image_name,\n",
    "    'ModelDataUrl': knn.model_data,\n",
    "}\n",
    "\n",
    "knn_model = sm.create_model(\n",
    "        ModelName = knn.latest_training_job.job_name,\n",
    "        ExecutionRoleArn = knn.role,\n",
    "        PrimaryContainer = primary_container)\n",
    "print(\"saved the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バッチ変換\n",
    "\n",
    "モデルによって作成された予測を確認するには、推論を作成し、予測が妥当かどうかを確認する必要があります。前回と同様のプロセスを繰り返し、商品の考えられるすべての組み合わせを使用してユーザーを 1 人ずつ確認できます。ただし、Amazon SageMaker では、データセット全体の推論を実行するために使用できるバッチ変換ジョブを利用できます。詳細については、[バッチ変換を使用してデータセット全体の推論を取得する](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) を参照してください。\n",
    "\n",
    "このセクションでは、バッチ変換を使用して、すべてのユーザーを対象に上位 100 件のレコメンデーションを予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Upload inference data to S3\n",
    "knn_batch_data_path = writeDatasetToProtobuf(knn_user_matrix,\n",
    "                                             bucket,\n",
    "                                             knn_prefix,\n",
    "                                             train_key,\n",
    "                                             \"dense\")\n",
    "print (\"Batch inference data path: \",knn_batch_data_path)\n",
    "\n",
    "# Initialize the transformer object\n",
    "transformer =sagemaker.transformer.Transformer(\n",
    "    base_transform_job_name=\"knn\",\n",
    "    model_name=knn_model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    output_path=knn_output_prefix,\n",
    "    accept=\"application/jsonlines; verbose=true\",\n",
    "    \n",
    ")\n",
    "\n",
    "# Start a transform job\n",
    "transformer.transform(knn_batch_data_path,\n",
    "                      content_type='application/x-recordio-protobuf',\n",
    "                      split_type='RecordIO')\n",
    "transformer.wait()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、予測を自由に調べることができるようになりました。まず、予測をダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions \n",
    "results_file_name = \"inference_output\"\n",
    "inference_output_file = \"knn/output/train_knn.out\"\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(bucket, inference_output_file, results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and load it to memory\n",
    "with open(results_file_name) as f:\n",
    "    results = f.readlines() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果には、100 件の最近傍映画の ID と対応する距離が含まれています。ユーザー番号 200 について、どのようになっているのかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_user_idx = 200\n",
    "u_one_json = json.loads(results[test_user_idx])\n",
    "recommended_movies = [int(movie_id) for movie_id in u_one_json['labels']]\n",
    "distances = [round(distance, 4) for distance in u_one_json['distances']]\n",
    "\n",
    "print(f'Recommended movie Ids for user #{test_user_idx} : {recommended_movies}')\n",
    "\n",
    "print(f'Movie distances for user #{test_user_idx} : {distances}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユーザー 200 の好みに最も近い映画を取得しました。次に、タイトルを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_200 = reduced_df[reduced_df.item.isin(recommended_movies)].product_title.unique()\n",
    "titles_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらをユーザー 200 のお気に入りの映画と比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.query('user==200 &amp; star_rating == 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題:** これらのレコメンデーションは妥当だと思いますか? そう思う理由、または思わない理由を説明してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(titles_200, titles.tail(100).product_title.unique()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**スーパーボーナス問題:** ユーザー 201 の予測を復元し、ユーザー 200 の予測と比較してください。まだ互いに相関関係にありますか? この手法は最初の回帰と比べて改善された手法だと思いますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the predictions for user 201\n",
    "\n",
    "test_user_idx = 201\n",
    "u_one_json = json.loads(results[test_user_idx])\n",
    "recommended_movies_201 = [int(movie_id) for movie_id in u_one_json['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out recommendations\n",
    "\n",
    "titles_201 = reduced_df[reduced_df.item.isin(recommended_movies_201)].product_title.unique()\n",
    "titles_201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two predictions\n",
    "\n",
    "overlap = np.isin(titles_200, titles_201).sum()\n",
    "print(f'The recommendations for \"user 201\" that are present in \"user 200\" are: {overlap} out of: {len(titles_200)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with user 201 likes\n",
    "\n",
    "reduced_df.query('user==201 &amp; star_rating == 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_idx = 900\n",
    "u_one_json = json.loads(results[test_user_idx])\n",
    "recommended_movies_900 = [int(movie_id) for movie_id in u_one_json['labels']]\n",
    "titles_900 = reduced_df[reduced_df.item.isin(recommended_movies_201)].product_title.unique()\n",
    "overlap_900 = np.isin(titles_200, titles_900).sum()\n",
    "print(f'The recommendations for \"user 900\" that are present in \"user 200\" are: {overlap} out of: {len(titles_200)}')\n",
    "reduced_df.query('user==900 &amp; star_rating == 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらのモデルを改善するために行えることはたくさんあります。例えば、評価以外の特徴量を追加すること、特徴量の選択を変えてみること、ハイパーパラメータをチューニングすること、モデルを変更することなどができます。最も高度なレコメンデーションアルゴリズムは、深層学習に基づいています。これを調べてみることもできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで終了です! ユーザーの上位 100 件の映画を教えてくれる正常に機能するレコメンダシステムが完成しました。ハイパーパラメータとデータを自由に最適化したり、操作したりして、レコメンダシステムをさらに改善できるかどうかを試してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "このノートブックでは、Amazon SageMaker の組み込みアルゴリズムのみを使用して、さまざまな手法でレコメンデーションシステムを作成しました。さまざまな形式のデータを準備し、特徴量エンジニアリングを行う方法を学習しました。トレーニング済みモデルの問題を特定し、さまざまな方法で問題を再構成して、最終結果を得ることができました。\n",
    "\n",
    "これでわかるように、モデルのトレーニングには、多くの手順、準備、検証が必要です。これは合理化されたプロセスではなく、反復的なプロセスです。このプロセスは、通常、以下の手順で構成される好ましい循環と考えることができます。\n",
    "\n",
    "- (ビジネス上の) 問題を定義する\n",
    "- 問題を機械学習の問題としてとらえる\n",
    "- データを準備し、特徴量エンジニアリングを実行する\n",
    "- モデルをトレーニングして評価する\n",
    "- モデルをデプロイする (推論)\n",
    "- モニタリングして評価する\n",
    "\n",
    "すべての手順には独自の課題があり、各手順では相互に必要なものが提供されます。したがって、モデルのトレーニングのみではなく、パイプライン全体に注意することが重要です。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
