{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題: クレジットカードの不正利用の予測 \n",
    "\n",
    "## ビジネスシナリオの概要\n",
    "あなたは多国籍銀行に勤務しています。ここ数か月で、クレジットカードの不正利用の被害に遭った顧客の数が大幅に増加しています。最近、主要な報道機関により、銀行で発生しているクレジットカードの不正利用に関する記事も発行されています。\n",
    "\n",
    "このような状況に対応するため、クレジットカードの不正取引によって自社が大きな被害を受ける前に、機械学習でその不正取引を特定することでこの問題の一部を解決するように指示されました。あなたは、過去のクレジットカード取引のデータセットにアクセスできます。このデータセットを使用して、取引が不正かどうかを予測する機械学習モデルをトレーニングできます。\n",
    "\n",
    "\n",
    "## このデータセットについて\n",
    "このデータセットには、2013 年 9 月に欧州のクレジットカード所有者によって行われた取引が含まれます。データセットに示されるのは、2 日間に行われた取引で、不正な取引と正当な取引の両方のサンプルが含まれています。\n",
    "\n",
    "### 特徴量\n",
    "データセットには、数値特徴量が 30 個以上が含まれます。この特徴量の大部分では、データの個人プライバシーの問題から、主成分分析 (PCA) 変換が実施されました。PCA で変換されていない特徴量は 'Time' と 'Amount' のみです。特徴量 'Time' には、データセット内の最初の取引から各取引までの間に経過した秒数が格納されています。特徴量 'Amount' は取引金額です。'Class' は応答またはターゲット変数で、不正の場合は値 '1' を取り、そうでない場合は '0' を取ります。\n",
    "\n",
    "特徴量: \n",
    "`V1, V2, ...V28`: PCA で取得した主成分\n",
    "\n",
    "PCA 以外の特徴量:\n",
    "- `Time`: データセット内の最初の取引から各取引までの間に経過した秒数、$T_x - t_0$\n",
    "- `Amount`: 取引金額。この特徴量は、サンプルに依存したコスト考慮型学習に使用できる \n",
    "- `Class`: ターゲット変数。`Fraud = 1` と `Not Fraud = 0`\n",
    "\n",
    "### データセットの属性\n",
    "ウェブサイト: https://www.openml.org/d/1597\n",
    "\n",
    "Twitter: https://twitter.com/dalpozz/status/645542397569593344\n",
    "\n",
    "作成者: Andrea Dal Pozzolo 氏、Olivier Caelen 氏、Gianluca Bontempi 氏\n",
    "出典: Credit card fraud detection - 2015 年 6 月 25 日\n",
    "公式引用: IEEE、Computational Intelligence and Data Mining (CIDM) のシンポジウムにて。Andrea Dal Pozzolo 氏、Olivier Caelen 氏、Reid A. Johnson 氏、Gianluca Bontempi 氏。Calibrating Probability with Undersampling for Unbalanced Classification、2015 年。\n",
    "\n",
    "このデータセットは、ビッグデータマイニングと不正検出に関して Worldline と ULB (Université Libre de Bruxelles) の Machine Learning Group (mlg.ulb.ac.be) が行った共同研究の際に収集され、分析されました。関連するトピックにおける現在および過去のプロジェクトの詳細については、http://mlg.ulb.ac.be/BruFence と http://mlg.ulb.ac.be/ARTML を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 1: 問題の定式化とデータ収集\n",
    "\n",
    "このプロジェクトを始めるにあたり、このシナリオにおけるビジネス上の問題と達成しようとしているビジネス目標を 2、3 文にまとめて、以下に入力します。これには、チームが目指す必要のあるビジネスメトリクスを含めます。その情報を定義したら、機械学習の問題文を明確に書き出します。最後に、これが表す機械学習のタイプに関するコメントを 1、2 文追加します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: これらの詳細の要約をプロジェクトプレゼンテーションに含めます。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ビジネスシナリオをひととおり読み通してから、以下を実行します\n",
    "\n",
    "### 1.機械学習がデプロイすべき適切なソリューションかどうか、また適切なソリューションである場合はその理由を判断します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.ビジネス上の問題、成功のメトリクス、求める機械学習の出力を定式化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.取り組んでいる機械学習の問題のタイプを特定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.使用しているデータの適切性を分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定\n",
    "\n",
    "注力する領域を特定したところで、問題を解決するための作業を開始できるようにセットアップしましょう。\n",
    "\n",
    "**注意:** このノートブックは `ml.m4.xlarge` ノートブックインスタンスで作成およびテストされました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various Python libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install imblearn\n",
    "!pip uninstall scikit-learn -y\n",
    "!pip install imbalanced-learn==0.7.0\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットをダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the file is already in the desired path or if it needs to be downloaded\n",
    "# Data source: https://www.openml.org/data/get_csv/1673544/phpKo8OWT\n",
    "import os\n",
    "import subprocess\n",
    "base_path = '/home/ec2-user/SageMaker/project/data/FraudDetection'\n",
    "file_path = '/fraud.csv'\n",
    "\n",
    "if not os.path.isfile(base_path + file_path):\n",
    "    subprocess.run(['mkdir', '-p', base_path])\n",
    "    subprocess.run(['aws', 's3', 'cp',\n",
    "                    's3://aws-tc-largeobjects/ILT-TF-200-MLDWTS/credit_card_project/',\n",
    "                    base_path,'--recursive'])\n",
    "else:\n",
    "    print('File already downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 2: データの前処理と可視化  \n",
    "このデータの前処理フェーズでは、データを探索して可視化し、データに対する理解を深める必要があります。まず、必要なライブラリをインポートし、データを pandas の DataFrame に読み込みます。その後、データを探索します。データセットのシェイプを確認し、作業している列と列のタイプ (数値、カテゴリ) を調べます。特徴量に対して基本的な統計を実行して、特徴量の平均と範囲を理解することを検討します。ターゲット列を詳細に調べて、その分布を判断します。\n",
    "\n",
    "### 考慮すべき具体的な質問\n",
    "1.特徴量に対して実行した基本的な統計からどのようなことを推測できますか? \n",
    "\n",
    "2.ターゲットクラスの分布から、どのようなことを推測できますか?\n",
    "\n",
    "3.データを探索することで推測できたことは他にありますか?\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: これらの質問や他の同様の質問に対する自分の回答の要約をプロジェクトプレゼンテーションに含めます。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV データを pandas の DataFrame に読み込みます。Python の組み込みの `read_csv` 関数 ([ドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)) を使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(<CODE>) # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの最初の 5 行を出力し、DataFrame を確認します。 \n",
    "\n",
    "**ヒント**: `<dataframe>.head()` 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class has a weird string instead of a boolean or numbers 0 and 1, so convert it to 0 and 1 \n",
    "\n",
    "mapped_class = {\"'0'\": 0, \"'1'\": 1}\n",
    "df['Class'] = df['Class'].map(lambda x: mapped_class[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if that worked\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**タスク**: データセットのすべての列 (`V1-V28`、`Time`、`Amount`、`Class`) を検証し、それらの列が上記で読み取ったものであることを確認します。 \n",
    "\n",
    "**ヒント**: DataFrame の列を確認するには、`<dataframe>.columns` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: 列タイプや null 値についてどのようなことがわかりましたか? 数値列またはカテゴリ列はいくつありますか? \n",
    "\n",
    "**ヒント**: 確認するには `info()` 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: pandas ライブラリと `Describe` 関数を使用して基本的な統計を実行してください。`amount` 特徴量の平均と標準偏差はどのようになっていますか? これらの数値からどのようなことを推測できますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: 不正であるレコードについて、`amount` の平均、標準偏差、最大値はどのようになっていますか?  \n",
    "\n",
    "**ヒント**: DataFrame で `mean()`、`std()`、`max()` の組み込み関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraud Statistics\")\n",
    "\n",
    "avg_amt = # Enter your code here\n",
    "std_dev = # Enter your code here\n",
    "max_amt = # Enter your code here\n",
    "\n",
    "print(f\"The average amount is {avg_amt}\")\n",
    "print(f\"The std deviation for amount is {std_dev}\")\n",
    "print(f\"The max amount is {max_amt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、ターゲット変数 `Class` を確認します。まず、この変数の分布を見つけることができます。\n",
    " \n",
    "**問題**: クラスの分布はどのようになっていますか?  \n",
    "\n",
    "**ヒント**: 分布を確認するには、`<dataframe>['column_name'].value_counts()` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: クラスの分布からどのようなことを推測できますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: レコードの総数に対する 0 のクラスの比率はどのくらいですか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを可視化する\n",
    "上記の部分でまだそうしていない場合には、以下のスペースを使用して、データの一部をさらに可視化できます。具体的には、`Amount`、`Time` などの特徴量の分布を確認します。また、データセットの特徴量間の線形相関を計算します。\n",
    "\n",
    "### 考慮すべき具体的な質問\n",
    "1.`Amount`、`Time` などの特徴量の分布を確認した結果、これらの特徴量はどの程度モデルに役立つと思われますか? これらの分布から推測できる、データの理解を深めるのに役立つと思われるものが何かありますか?\n",
    "\n",
    "2.不正であるとラベル付けされたデータのみに注目した場合、`Amount`、`Time` などの特徴量の分布に違いはありますか?\n",
    "\n",
    "3.データセットの特徴量の中で相関の高いものはありますか? ある場合、次に行うステップは何ですか?\n",
    "\n",
    "以下のセルを使用してデータを可視化し、これらの質問や他の関心を持つ質問に回答します。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: この質問や同様の質問に対する自分の回答の要約をプロジェクトプレゼンテーションに含めます。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡単な散布図から始めます。V1 とV2 のグラフを作成します。散布図を作成する方法の詳細については、[Matplotlib のドキュメント](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.plot.html) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(<CODE>, <CODE>, '.') # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一部の特徴量の分布を確認します。`sns.distplot()` を使用し、`Amount`、`Time` などの個別の特徴量の分布を見つけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(<CODE>) # Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: `Time` 特徴量は何らかの点で役立ちますか? 分布をもう一度確認してください。散布図からどのようなことを推測できますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ヒストグラムとカーネル密度推定 (KDE) を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Class'] == 1]['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: 不正の場合、`Amount` 列の分布はどのようになっていますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(<CODE>)# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、`pairplot` という seaborn 関数を使用して分布を確認してみましょう。`pairplot` では、散布図のグリッドが作成され、データセットの各特徴量が X 軸として 1 回、Y 軸として 1 回使用されます。このグリッドの対角線は、その特徴量のデータの分布を示しています。\n",
    "\n",
    "`V1`、`V2`、`V2`、`V4`、`Class` の pairplot を確認してみましょう。この図から何がわかりますか? これらの特徴量から不正な取引と不正でない取引を区別できますか?  \n",
    "\n",
    "**ヒント**: 列 `V1`、`V2`、`V4`、`Class` で新しい DataFrame を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df = # Enter your code here\n",
    "sns.pairplot(new_df, hue=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用した特徴量が小さいサブセットについては、不正な取引と不正でない取引を区別する方法があることがわかりますが、どの特徴量に基づく場合でも、区別するのは簡単ではありません。\n",
    "\n",
    "では、これらの特徴量が相互にどのように影響し合うのかを見てみましょう。pandas の `<dataframe>.corr()` 関数を使用して、データセットのすべての特徴量間の線形相関を計算します。相関関係は常に簡単に可視化できます。seaborn のヒートマップ (`sns.heatmap`) 関数で `annot` フラグを `True` に設定し、相関関係のデータを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,15))\n",
    "correlation_matrix = # Enter your code here\n",
    "sns.heatmap(correlation_matrix, annot=True,fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: 相関がある特徴量については、モデルをトレーニングする前にいずれか 1 つを削除する必要があります。削除できる特徴量はありますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">ラボ 2 の終わり</span>\n",
    "\n",
    "ローカルコンピュータにプロジェクトファイルを保存します。次の一連のステップを実行します。\n",
    "\n",
    "1.ページ上部にある [**File**] メニューをクリックします。\n",
    "\n",
    "1.[**Download as**] を選択し、[**Notebook(.ipynb)**] をクリックします。 \n",
    "\n",
    "これにより、現在のノートブックがコンピュータのデフォルトのダウンロードフォルダにダウンロードされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 3: モデルのトレーニングと評価\n",
    "\n",
    "データセットを DataFrame から機械学習アルゴリズムで使用できる形式に変換するときに、実行する必要がある準備手順があります。Amazon SageMaker の場合、以下の手順を実行する必要があります。\n",
    "\n",
    "1.`sklearn.model_selection.train_test_split` を使用し、データを `train_data`、`validation_data`、`test_data` に分割します。   \n",
    "2.Amazon SageMaker トレーニングジョブで使用できる適切なファイル形式にデータセットを変換します。これは CSV ファイルまたは record protobuf のいずれかです。詳細については、[トレーニングの共通データ形式](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html) を参照してください。   \n",
    "3.Amazon S3 バケットにデータをアップロードします。\n",
    "\n",
    "以下のセルを使用して、これらの手順を完了します。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: このフェーズでの主な決定事項をプロジェクトプレゼンテーションに記録します。</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- トレーニングデータとモデルデータに使用する Amazon Simple Storage Service (Amazon S3) バケットとプレフィックス (?)。これは、ノートブックインスタンス、トレーニング、ホスティングと同じリージョン内にある必要があります。\n",
    "- トレーニングとホスティング用にデータへのアクセス権を付与するために使用する AWS Identity and Access Management (IAM) ロールの [Amazon リソースネーム (ARN)](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html)。これらの作成方法については、ドキュメントを参照してください。\n",
    "\n",
    "**注意:** ノートブックインスタンス、トレーニング、またはホスティングに複数のロールが必要な場合、`get_execution_role()` コールを適切で完全な IAM ロールの ARN 文字列に置き換えます。\n",
    "\n",
    "**`<LabBucketName>`** をラボアカウントに用意されたリソース名に置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "\n",
    "# Instantiate an Amazon SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Get the Amazon SageMaker role \n",
    "role = get_execution_role()\n",
    "\n",
    "# Bucket name\n",
    "bucket = <LabBucketName>\n",
    "\n",
    "# Get the image URI for the container that includes the linear learner algorithm\n",
    "container = image_uris.retrieve('linear-learner',boto3.Session().region_name)\n",
    "\n",
    "print(f'Session {sess}')\n",
    "print(f'The role is {role}')\n",
    "print(f'The container is {role} in the {boto3.Session().region_name} region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_training_sets(data):\n",
    "    \"\"\"\n",
    "    Convert data frame to train, validation and test\n",
    "    params:\n",
    "        data: The dataframe with the dataset to be split\n",
    "    Returns:\n",
    "        train_features: Training feature dataset\n",
    "        test_features: Test feature dataset \n",
    "        train_labels: Labels for the training dataset\n",
    "        test_labels: Labels for the test dataset\n",
    "        val_features: Validation feature dataset\n",
    "        val_labels: Labels for the validation dataset\n",
    "    \"\"\"\n",
    "    # Extract the target variable from the dataframe and convert the type to float32\n",
    "    ys = np.array(<CODE>).astype(\"float32\") # Enter your code here\n",
    "    \n",
    "    # Drop all the unwanted columns including the target column\n",
    "    drop_list = # Enter your code here\n",
    "    \n",
    "    # Drop the columns from the drop_list and convert the data into a NumPy array of type float32\n",
    "    xs = np.array(data.drop(<CODE>, axis=1)).astype(\"float32\")# Enter your code here\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Use the sklearn function train_test_split to split the dataset in the ratio train 80% and test 20%\n",
    "    # Example: train_test_split(x, y, test_size=0.3)\n",
    "    train_features, test_features, train_labels, test_labels = # Enter your code here\n",
    "    \n",
    "    # Use the sklearn function again to split the test dataset into 50% validation and 50% test\n",
    "    val_features, test_features, val_labels, test_labels = # Enter your code here\n",
    "    \n",
    "    return train_features, test_features, train_labels, test_labels, val_features, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to create your datasets\n",
    "train_features, test_features, train_labels, test_labels, val_features, val_labels = create_training_sets(df)\n",
    "\n",
    "print(f\"Length of train_features is: {<CODE>}\")\n",
    "print(f\"Length of train_labels is: {<CODE>}\")\n",
    "print(f\"Length of val_features is: {<CODE>}\")\n",
    "print(f\"Length of val_labels is: {<CODE>}\")\n",
    "print(f\"Length of test_features is: {<CODE>}\")\n",
    "print(f\"Length of test_labels is: {<CODE>}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプル出力\n",
    "```\n",
    "Length of train_features is: (227845, 29)  \n",
    "Length of train_labels is: (227845,)  \n",
    "Length of val_features is: (28481, 29)  \n",
    "Length of val_labels is: (28481,)  \n",
    "Length of test_features is: (28481, 29)  \n",
    "Length of test_labels is: (28481,)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのトレーニング\n",
    "\n",
    "まず、1 つの ml.m4.xlarge インスタンスで `predictor_type='binary_classifier'` パラメータを使用して LinearLearner 分類器をインスタンス化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "import boto3\n",
    "\n",
    "# Instantiate the LinearLearner estimator object\n",
    "num_classes = # Enter your code here\n",
    "\n",
    "# Instantiate the LinearLearner estimator 'binary classifier' object with one ml.m4.xlarge instance\n",
    "linear = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               instance_count=<CODE>,\n",
    "                                               instance_type=<CODE>,\n",
    "                                               predictor_type=<CODE>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルコード\n",
    "```\n",
    "num_classes = len(pd.unique(train_labels))\n",
    "linear = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                              train_instance_count=1,\n",
    "                                              train_instance_type='ml.m4.xlarge',\n",
    "                                              predictor_type='binary_classifier',\n",
    "                                             )\n",
    "                                              \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形学習の場合、トレーニングデータは protobuf または CSV のコンテンツタイプで受け入れ、推論リクエストは protobuf、CSV、JSON のいずれかのコンテンツタイプで受け入れます。トレーニングデータは特徴量と正解ラベルで構成されるのに対し、推論リクエストのデータは特徴量のみで構成されます。本番パイプラインでは、データを Amazon SageMaker の protobuf 形式に変換し、Amazon S3 に保存することをお勧めします。ただし、すばやく開始できるように、AWS では、データセットがローカルメモリに収まるほど小さい場合には `record_set` という便利なメソッドを利用して、変換とアップロードを実行できます。このメソッドは、既にお使いのような NumPy 配列に対応しているため、ここではそれを使ってみましょう。`RecordSet` オブジェクトでは、データの一時的な Amazon S3 の場所を記録します。`estimator.record_set` 関数を使用して、トレーニング、検証、テストのレコードを作成します。次に、`estimator.fit` 関数を使用してトレーニングジョブを開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create train, val, test records\n",
    "train_records = linear.record_set(<CODE>,<CODE>, channel='train')# Enter your code here\n",
    "val_records = linear.record_set(<CODE>,<CODE>, channel='validation')# Enter your code here\n",
    "test_records = linear.record_set(<CODE>,<CODE>, channel='test')# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、アップロードしたデータセットでモデルをトレーニングしましょう。\n",
    "\n",
    "### サンプルコード\n",
    "```\n",
    "linear.fit([train_records,val_records,test_records], wait=True, logs='All')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the classifier\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの評価\n",
    "このセクションでは、トレーニング済みモデルを評価します。まず、`estimator.deploy` 関数で `initial_instance_count= 1` と `instance_type= 'ml.m4.xlarge'` を指定し、モデルを Amazon SageMaker にデプロイします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ホストされたエンドポイントが実行されたので、http POST リクエストを作成することで、モデルからリアルタイム予測を簡単に行うことができます。ただし、その前に、エンドポイントの背後にあるモデルに `test_features` NumPy 配列を渡すために、シリアライザとデシリアライザを設定する必要があります。また、モデルの混同行列を計算し、モデルがテストデータでどのように動作したのかを視覚的に評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score\n",
    "#from sagemaker.predictor import csv_serializer, json_deserializer, numpy_deserializer\n",
    "#from sagemaker.predictor import csv_deserializer\n",
    "\n",
    "def predict_batches(model, features, labels, split=200):\n",
    "    \"\"\"\n",
    "    Predict datapoints in batches specified by the split.\n",
    "    The data will be split into <split> parts and model.predict is called \n",
    "    on each part\n",
    "    Arguments:\n",
    "        model: The model that you will use to call predict function\n",
    "        features: The dataset to predict on\n",
    "        labels: The true value of the records\n",
    "        split: Number of parts to split the data into\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    split_array = np.array_split(features, split)\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        predictions += model.predict(array).label\n",
    "\n",
    "    # preds = np.array([p['predicted_label'] for p in predictions])\n",
    "    preds = [i.label['predicted_label'].float32_tensor.values[0] for i in predictions]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    \n",
    "    # Calculate precision\n",
    "    precision = precision_score(labels, preds)\n",
    "    print(f'Precision: {precision}')\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = recall_score(labels, preds)\n",
    "    print(f'Recall: {recall}')\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(index=labels, columns=np.round(preds), rownames=['True'], colnames=['predictions']).astype(int)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エンドポイントが 'InService' になったので、テストセットでのモデルのパフォーマンスを評価します。テストセットでのパフォーマンスとトレーニングセットでのパフォーマンスを比較します。\n",
    "\n",
    "### 考慮すべき主な質問:\n",
    "1.テストセットでのモデルのパフォーマンスはトレーニングセットでのパフォーマンスと比べてどのように異なりますか? この比較からどのようなことを推測できますか? \n",
    "\n",
    "2.正解率、適合率、再現率などのメトリクスの結果に明らかな違いはありますか? ある場合、そのような違いが見られる理由は何だと思われますか? \n",
    "\n",
    "3.ビジネスの状況と目標を考えると、ここで考慮すべき最も重要なメトリクスはどれですか? それはなぜですか?\n",
    "\n",
    "4.最も重要だと考えるメトリクスの結果は、ビジネスの観点でのニーズを十分に満たすものですか? そうでない場合、次のイテレーション (次の特徴量エンジニアリングのセクション) の際に何を変更できると思いますか? \n",
    "\n",
    "以下のセルを使用して、これらの質問や他の質問に答えてください。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: これらの質問やこのセクションで回答する他の同様の質問に対する回答をプロジェクトプレゼンテーションに記録します。主な詳細と決定事項をプロジェクトプレゼンテーションに記録します。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches(linear_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストセットと同様に、トレーニングセットのメトリクスを確認することもできます。メトリクスは、ログの上部に表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_batches(linear_predictor, train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete inference endpoint\n",
    "sagemaker.Session().delete_endpoint(linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:red\">ラボ 3 の終わり</span>\n",
    "\n",
    "ローカルコンピュータにプロジェクトファイルを保存します。次の一連のステップを実行します。\n",
    "\n",
    "1.ページ上部にある [**File**] メニューをクリックします。\n",
    "\n",
    "1.[**Download as**] を選択し、[**Notebook(.ipynb)**] をクリックします。 \n",
    "\n",
    "これにより、現在のノートブックがコンピュータのデフォルトのダウンロードフォルダにダウンロードされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# イテレーション 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ 4: 特徴量エンジニアリング\n",
    "\n",
    "これで、モデルのトレーニングと評価の 1 回目のイテレーションを完了しました。モデルで最初に得られた結果はビジネス上の問題を解決するにはおそらく不十分だったと仮定すると、モデルのパフォーマンスを改善できるようにするためにデータに関して何を変更できると思いますか?\n",
    "\n",
    "### 考慮すべき主な質問:\n",
    "1.2 つのメインクラス (不正と不正でない) の均衡はモデルのパフォーマンスにどう影響する可能性がありますか?\n",
    "2.データセットの均衡を調整することは、特徴量間の相関関係に影響しますか?\n",
    "3.この段階で、モデルのパフォーマンスに良い影響を与える可能性があり、実行できる特徴量削減の手法はありますか? \n",
    "4.特徴量エンジニアリングを実行した結果、1 回目のイテレーションと比べてモデルのパフォーマンスはどうなりますか?\n",
    "\n",
    "以下のセルを使用し、上記の質問に従って、モデルのパフォーマンスが改善すると考えられる特徴量エンジニアリングの手法を実行します。必要に応じてセルを挿入および削除します。\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: 主な決定事項とこのセクションで使用する手法をプロジェクトプレゼンテーションに記録します。また、モデルを再び評価した後に取得する新しいパフォーマンスメトリクスも記録します。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始する前に、適合率と再現率が約 80% であるのに対し、精度が 99% である理由を考えてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度は、モデルによって正しく認識されたサンプルの数を使用して計算されます。ただし、サンプルのほとんどは実際のところ陰性であるため、この非常に不均衡なデータセットですべての例を 0 と予測しても、約 99.827% の精度を得ることができます。データセットが不均衡であると、アルゴリズムのパフォーマンスに問題が生じる可能性があります。このため、モデルをトレーニングする前にデータの不均衡に対処しておくと便利です。\n",
    "\n",
    "**問題**: データセットの不均衡の問題をどのように解決しますか?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: データセットのシェイプをもう一度出力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Length of train_features is: {train_features.shape}\")\n",
    "print(f\"Length of train_labels is: {train_labels.shape}\")\n",
    "print(f\"Length of val_features is: {val_features.shape}\")\n",
    "print(f\"Length of val_labels is: {val_labels.shape}\")\n",
    "print(f\"Length of test_features is: {test_features.shape}\")\n",
    "print(f\"Length of test_labels is: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sns.countplot` を使用し、データセットの元の分布を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Class'])\n",
    "plt.title('Original Distribution of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_features` を DataFrame に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(<CODE>, columns = df.columns.drop(['Time','Class'])) # Enter your code here\n",
    "df_train['Target'] = # Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不均衡なデータセットを処理するには、主に以下の 2 つの方法があります。\n",
    "\n",
    "- 陽性サンプルを追加するオーバーサンプリング\n",
    "    - ランダムオーバーサンプリング\n",
    "    - [SMOTE (Synthetic minority oversampling technique)](https://arxiv.org/abs/1106.1813)\n",
    "- 陰性サンプルを減らすアンダーサンプリング\n",
    "    - ランダムアンダーサンプリング\n",
    "    - クラスタリング手法を使用して重心を生成\n",
    "\n",
    "`Imbalanced-learn` というライブラリを使用してデータセットをサンプリングできます。`imbalanced-learn` は、クラス間が非常に不均衡なデータセットでよく使用される、さまざまなリサンプリング手法を提供する Python パッケージです。scikit-learn と互換性があり、scikit-learn-contrib プロジェクトの一部です。詳細については、[imbalanced-learn API のドキュメント](https://imbalanced-learn.org/stable/introduction.html) を参照してください。\n",
    "\n",
    "この例では、最初にアンダーサンプリングを選択します。以下の手順を実行し、均衡の取れたデータセットを作成します。\n",
    "\n",
    "1.すべての陽性サンプルを使用して新しい DataFrame `fraud_df` を作成します。\n",
    "2.もう 1 つの DataFrame `non_fraud_df` を作成し、`fraud_df` DataFrame と同じ数の `dataframe.sample` を使用し、`random_state=235` を指定します。\n",
    "3.両方の DataFrame を連結して新しい DataFrame `balanced_df` を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows in df_train dataframe where Target == 1\n",
    "fraud_df = # Enter your code here\n",
    "\n",
    "# Select the rows in df_train dataframe where Target == 0\n",
    "non_fraud_df = # Enter your code here\n",
    "\n",
    "balanced_df = pd.concat([fraud_df, non_fraud_df], ignore_index=True, sort=False)\n",
    "\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sns.countplot()` を使用し、分布とシェイプを再度確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "plt.title('Original Distribution of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングを確認する前に、t 分布型確率的近傍埋め込み法 (t-SNE) などの特徴量削減の手法をデータセットで使用するとどうなるかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(<CODE>)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1],\n",
    "            c = balanced_df['Target'],\n",
    "            s = 1,\n",
    "            cmap = ListedColormap(['Red', 'Blue']),\n",
    "            linewidths=1)\n",
    "\n",
    "plt.title('Red: 0 , Blue: 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: t-SNE を使用することは、不正な取引と不正でない取引を区別するのに役立ちますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいデータを入手したので、前のデータとこのデータでは相関行列がどのようになるのかを比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use the subsample in the correlation\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# Use the original dataset to find the correlations between the features\n",
    "correlation_matrix_before = # Enter your code here\n",
    "sns.heatmap(correlation_matrix_before, annot=True,fmt=\".2f\")\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# Use the original dataset to find the correlations between the features\n",
    "correlation_matrix_after = # Enter your code here\n",
    "sns.heatmap(correlation_matrix_after, annot=True,fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: この 2 つの相関行列からどのようなことを推測できますか? 違いが見られる場合、違いがある理由を分析できますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: データに相関関係があるために、削除する列はありますか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相関関係があるため、相関が 0.9 を上回る相関データを削除しましょう。以下のセルを実行して、`V17` 列と `V18` 列を削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df_drop = balanced_df.drop(columns=['V17','V18'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "均衡の取れたこの新しいデータセットを使用して、トレーニング、デプロイ、評価を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルコード\n",
    "\n",
    "```\n",
    "# instantiate the LinearLearner estimator object\n",
    "num_classes = len(pd.unique(train_labels))\n",
    "linear_estimator_balanced = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               instance_count=1,\n",
    "                                               instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='binary_classifier')\n",
    "\n",
    "\n",
    "train_records_bal = linear_estimator_balanced.record_set(balanced_df.drop(['Target'], axis=1).values,\n",
    "                                                balanced_df['Target'].values,\n",
    "                                                channel='train')\n",
    "val_records_bal = linear_estimator_balanced.record_set(val_features, val_labels, channel='validation')\n",
    "test_records_bal = linear_estimator_balanced.record_set(test_features, test_labels, channel='test')\n",
    "\n",
    "linear_estimator_balanced.fit([train_records_bal, val_records_bal, test_records_bal])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分布を構成するサンプルの数を減らしたので、再現率は上昇せず、低下しました。高い再現率が必要なため、別の戦略を試してみましょう。\n",
    "\n",
    "SMOTE を使用して陽性サンプルの数を増やしてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# Drop the columns from your original dataset that you don't need\n",
    "X = # Enter your code here\n",
    "\n",
    "# Use the class feature as the labels\n",
    "y = # Enter your code here\n",
    "\n",
    "sm = SMOTE(random_state=35)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**オプション**: 新しいデータセットを Pandas の DataFrame に変換し、データのシェイプと分布を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df = pd.DataFrame(<CODE>, # Enter your code here\n",
    "                        columns = df.drop(['Class', 'Time'], axis=1).columns) \n",
    "smote_df['Class'] = # Enter your code here\n",
    "smote_df['Time'] = df['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニング、テスト、検証の新しいデータセットを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels, val_features, val_labels = create_training_sets(<CODE>))# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいデータセットを使用してモデルをトレーニングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(pd.unique(train_labels))\n",
    "linear_estimator_smote = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='binary_classifier')\n",
    "\n",
    "\n",
    "train_records_smote = linear_estimator_smote.record_set(train_features, train_labels, channel='train')\n",
    "val_records_smote = linear_estimator_smote.record_set(val_features, val_labels, channel='validation')\n",
    "test_records_smote = linear_estimator_smote.record_set(test_features, test_labels, channel='test')\n",
    "\n",
    "linear_estimator_smote.fit([train_records_smote, val_records_smote, test_records_smote])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: トレーニングジョブを評価することで、どのようなことを推測できますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータの最適化\n",
    "モデルのチューニングフェーズのもう 1 つの要素は、ハイパーパラメータの最適化です。このセクションでは、ハイパーパラメータをチューニングし、チューニングによってモデルのパフォーマンスがどの程度向上するのかを確認します。以下のテンプレートコードを使用すると、Amazon SageMaker のハイパーパラメータチューニングジョブを簡単に実行して、評価メトリクスを確認できます。以下の質問について考えながら、このセクションの残りの部分を進めてください。\n",
    "\n",
    "### 考慮すべき主な質問:\n",
    "1.チューニングジョブのタイミングが増えるにつれ、選択した目標メトリクスの結果はどのように変化しますか? 取得しているさまざまな目標メトリクスと時間の関係はどのようなものですか? \n",
    "2.目標メトリクスと個別のハイパーパラメータの相関関係はどのようになっていますか? 目標メトリクスと強い相関関係にあるハイパーパラメータはありますか? ある場合、この強い相関関係を利用するために何ができますか?\n",
    "3.ハイパーパラメータをチューニングした後で、モデルのパフォーマンスを分析してください。現在のパフォーマンスは、ビジネス上の問題を解決するために必要なパフォーマンスとして十分ですか?\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: 主な決定事項とこのセクションで使用する手法をプロジェクトプレゼンテーションに記録します。また、モデルを再び評価した後に取得する新しいパフォーマンスメトリクスも記録します。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {'wd': ContinuousParameter(<CODE>, <CODE>),\n",
    "                        'l1': ContinuousParameter(<CODE>, <CODE>),\n",
    "                        'learning_rate': ContinuousParameter(<CODE>, <CODE>)\n",
    "                        }\n",
    "\n",
    "objective_metric_name = <CODE>\n",
    "\n",
    "tuner = HyperparameterTuner(<ENTER your estimator name>,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=3)\n",
    "\n",
    "tuner.fit([<CODE>], include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータのチューニングジョブの進行状況を追跡する\n",
    "\n",
    "チューニングジョブを開始したら、`describe_tuning_job` API を呼び出して進行状況を確認できます。`describe-tuning-job` からの出力は JSON オブジェクトで、チューニングジョブの現在の状態に関する情報が含まれます。`list_training_jobs_for_tuning_job` を呼び出すと、チューニングジョブによって開始されたトレーニングジョブの詳細なリストを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.Session().client('sagemaker')\n",
    "tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "while status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "    job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "    print(\"%d training jobs have completed\" % job_count)\n",
    "    \n",
    "    time.sleep(180)\n",
    "\n",
    "    tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)\n",
    "    status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "    \n",
    "print(\"\\n\\n All training jobs have completed\")\n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "if tuning_job_result.get('BestTrainingJob',None):\n",
    "    print(\"Best model found so far:\")\n",
    "    pprint(tuning_job_result['BestTrainingJob'])\n",
    "else:\n",
    "    print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### すべての結果を DataFrame として取得する\n",
    "\n",
    "すべてのトレーニングジョブのハイパーパラメータと目標メトリクスのリストを作成し、目標メトリクスが最も高いトレーニングジョブを見つけることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df['FinalObjectiveValue'] > -float('inf')]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values('FinalObjectiveValue', ascending=is_minimize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\":min(df['FinalObjectiveValue']),\"highest\": max(df['FinalObjectiveValue'])})\n",
    "        pd.set_option('display.max_colwidth', -1) # Don't truncate TrainingJobName        \n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "        \n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**: モデルのチューニングは役に立ちますか?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時間の経過に伴って変化するチューニングジョブの結果を確認する\n",
    "\n",
    "ここでは、チューニングジョブが進むにつれて、目標メトリクスがどのように変化するのかを確認します。ベイズ戦略では、通常は結果が向上する傾向にありますが、アルゴリズムでは、既知の良好な領域の利用を基準にして、パラメータ空間の新しい領域の利用のバランスを取る必要があるため、この向上は一定ではありません。このため、探索空間の複雑さに対してトレーニングジョブの数が足りているかどうかと思うかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "class HoverHelper():\n",
    "\n",
    "    def __init__(self, tuning_analytics):\n",
    "        self.tuner = tuning_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            (\"FinalObjectiveValue\", \"@FinalObjectiveValue\"),\n",
    "            (\"TrainingJobName\", \"@TrainingJobName\"),\n",
    "        ]\n",
    "        for k in self.tuner.hyperparameter_ranges().keys():\n",
    "            tooltips.append( (k, \"@{%s}\" % k) )\n",
    "\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "\n",
    "    def tools(self, standard_tools='pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset'):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "\n",
    "hover = HoverHelper(tuner)\n",
    "\n",
    "p = figure(plot_width=900, plot_height=400, tools=hover.tools(), x_axis_type='datetime')\n",
    "p.circle(source=df, x='TrainingStartTime', y='FinalObjectiveValue')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標メトリクスと個別のハイパーパラメータの相関関係を分析する\n",
    "\n",
    "チューニングジョブが完了したので、目標メトリクスとチューニングするよう選択した個別のハイパーパラメータ間の相関関係を見てみましょう。この相関関係を理解すると、特定のハイパーパラメータの検索範囲を調節して、別のチューニングジョブを開始した方がよいかどうかを判断できます。例えば、目標メトリクスと数値ハイパーパラメータの間に好ましい傾向が見られる場合は、次のチューニングジョブでそのハイパーパラメータのチューニング範囲をより高く設定することをお勧めします。\n",
    "\n",
    "以下のセルを実行すると、各ハイパーパラメータのグラフが描画され、目標メトリクスとの相関関係が示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = tuner_analytics.tuning_ranges\n",
    "figures = []\n",
    "for hp_name, hp_range in ranges.items():\n",
    "    categorical_args = {}\n",
    "    if hp_range.get('Values'):\n",
    "        # This is marked as categorical.Check if all options are actually numbers.\n",
    "        def is_num(x):\n",
    "            try:\n",
    "                float(x)\n",
    "                return 1\n",
    "            except:\n",
    "                return 0           \n",
    "        vals = hp_range['Values']\n",
    "        if sum([is_num(x) for x in vals]) == len(vals):\n",
    "            # Bokeh has issues plotting a \"categorical\" range that's actually numeric, so plot as numeric\n",
    "            print(\"Hyperparameter %s is tuned as categorical, but all values are numeric\" % hp_name)\n",
    "        else:\n",
    "            # Set up extra options for plotting categoricals.A bit tricky when they're actually numbers.\n",
    "            categorical_args['x_range'] = vals\n",
    "\n",
    "    # Now plot it\n",
    "    p = figure(plot_width=600, plot_height=600,\n",
    "               title=\"Objective vs %s\" % hp_name,\n",
    "               tools=hover.tools(),\n",
    "               x_axis_label=hp_name, y_axis_label=objective_name,\n",
    "               **categorical_args)\n",
    "    p.circle(source=df, x=hp_name, y='FinalObjectiveValue')\n",
    "    figures.append(p)\n",
    "show(bokeh.layouts.Column(*figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを最終モデルとしてデプロイし、テストセットで評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_deploy = tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches(tuned_model_deploy, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches(tuned_model_deploy, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オプション: XGBoost アルゴリズムを試す\n",
    "トレーニングに移動し、まず XGBoost アルゴリズムコンテナの場所を指定する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'}\n",
    "\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker/xgboost-creditcard'\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "container = image_uris.retrieve('xgboost',boto3.Session().region_name, '1.0-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、CSV ファイル形式でトレーニングを行うため、トレーニング関数で Amazon S3 内のファイルへのポインタとして使用できる s3_inputs を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_balanced = balanced_df.drop(['Target'], axis=1).values\n",
    "train_labels_balanced = balanced_df['Target'].values\n",
    "\n",
    "train_features_label = np.insert(train_features_balanced, 0, train_labels_balanced, axis=1)\n",
    "val_features_label = np.insert(val_features, 0, val_labels, axis=1)\n",
    "test_features_label = np.insert(test_features, 0, test_labels, axis=1)\n",
    "\n",
    "np.savetxt(\"train.csv\", train_features_label, delimiter=\",\")\n",
    "np.savetxt(\"validation.csv\", val_features_label, delimiter=\",\")\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用するトレーニングインスタンスのタイプや数などのパラメータと XGBoost ハイパーパラメータを指定できます。主要ないくつかのハイパーパラメータは以下のとおりです。\n",
    "\n",
    "- `max_depth`: アルゴリズム内に構築する各ツリーの深さを制御します。ツリーが深くなると、適合は向上しますが、計算コストが高くなり、過剰適合が生じる可能性もあります。通常、多数の浅い木と少数の深い木の間でモデルのパフォーマンスのトレードオフを検討する必要があります。\n",
    "- `subsample`: トレーニングデータのサンプリングを制御します。この手法は過剰適合を減らすのに役立ちますが、設定が低すぎるとモデルにデータが足りなくなる可能性があります。\n",
    "- `num_round`: ブースティングのラウンド数を制御します。これは、基本的に、前のイテレーションの残差を使用してトレーニングされる後続のモデルです。この場合も、ラウンド数を増やすほどトレーニングデータの適合は向上しますが、計算コストが高くなったり、過剰適合が生じたりする可能性があります。\n",
    "- `eta`: ブースティングの各ラウンドの積極性を制御します。値が大きいほど、ブースティングは消極的になります。\n",
    "- `gamma`: ツリーをどの程度積極的に成長させるかを制御します。値が大きいほど、消極的なモデルになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=10,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=1,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='auc',\n",
    "                        num_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、推定器にトレーニングパラメータを指定する必要があります。以下のようなパラメータを指定します。\n",
    "\n",
    "- XGBoost アルゴリズムコンテナ\n",
    "- 使用する IAM ロール\n",
    "- トレーニングインスタンスのタイプと数\n",
    "- 出力データ用の Amazon S3 の場所\n",
    "- アルゴリズムのハイパーパラメータ\n",
    "\n",
    "`.fit()` 関数を使用して、出力データ用の Amazon S3 の場所を指定します。この場合、トレーニングセットと検証セットの両方が渡されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホスティング\n",
    "\n",
    "データで XGBoost アルゴリズムをトレーニングしました。次に、リアルタイムエンドポイントの背後でホストされているモデルをデプロイします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを Amazon SageMaker にデプロイします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import CSVSerializer\n",
    "\n",
    "xgb_predictor = # Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_xgboost(model, data, labels, rows=500):\n",
    "    \n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "        \n",
    "    preds = np.fromstring(predictions[1:], sep=',')\n",
    "    confusion_matrix = pd.crosstab(index=labels, columns=np.round(preds), rownames=['True'], colnames=['predictions']).astype(int)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix') \n",
    "\n",
    "predict_xgboost(xgb_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges_xgb = {'eta': ContinuousParameter(0.01, 0.2),\n",
    "                         'max_depth': IntegerParameter(3, 9),\n",
    "                         'gamma': IntegerParameter(0, 5),\n",
    "                         'min_child_weight': IntegerParameter(2, 6),\n",
    "                         'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                         'colsample_bytree': ContinuousParameter(0.5, 0.9)}\n",
    "\n",
    "objective_metric_name_xgb = 'validation:auc'\n",
    "\n",
    "tuner_xgb = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name_xgb,\n",
    "                            hyperparameter_ranges_xgb,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=1)\n",
    "\n",
    "tuner_xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.Session().client('sagemaker')\n",
    "tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner_xgb.latest_tuning_job.job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "while status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "    job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "    print(\"%d training jobs have completed\" % job_count)\n",
    "    \n",
    "    time.sleep(180)\n",
    "\n",
    "    tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner_xgb.latest_tuning_job.job_name)\n",
    "    status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "    \n",
    "print(\"Training jobs have completed\")\n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チューニング済みのモデルを Amazon SageMaker にデプロイします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor_tuned = tuner_xgb.deploy(initial_instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       serializer=CSVSerializer() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgboost(xgb_predictor_tuned, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "モデルのトレーニングと評価のイテレーションを何回か行いました。ここで、もう少し時間があることを想定して、このプロジェクトについてまとめ、これまでに学んだこと、今後どのような手順を実行するのかについてよく考えます。以下のセルを使用して、これらの質問や他の関連する質問に回答してください。\n",
    "\n",
    "1.モデルのパフォーマンスはビジネス目標を満たしていますか? 満たしていない場合、チューニングにさらに多くの時間をかけられるとしたら別にやってみたいことが何かありますか?\n",
    "2.データセット、特徴量、ハイパーパラメータを変更すると、モデルはどの程度改善しましたか? このプロジェクト全体で採用した手法のうち、モデルが最も改善されたと感じたのはどの手法ですか?\n",
    "3.このプロジェクト全体で直面した最大の課題は何でしたか?\n",
    "4.パイプラインのフェーズに関する質問のうち、理解できていないままの質問はどのようなものですか?\n",
    "5.このプロジェクトで機械学習について学んだ最も重要なことは何ですか? (3 つ挙げてください)\n",
    "\n",
    "#### <span style=\"color: blue;\">プロジェクトプレゼンテーション: この質問に対する自分の回答の要約をプロジェクトプレゼンテーションに含めます。この時点でプロジェクトプレゼンテーションに使用するメモをすべてまとめ、クラスで結果を発表する準備をします。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
